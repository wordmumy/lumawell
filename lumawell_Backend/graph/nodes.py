# graph/nodes.py
import os, re, json
from pathlib import Path
from typing import Optional, List, Dict, Tuple
import random
from dotenv import load_dotenv
load_dotenv(override=True)
from pydantic import BaseModel
from openai import OpenAI
from langgraph.graph import MessagesState
from langchain_core.messages import AIMessage

# ---- ç»Ÿä¸€æ—¶åŒºä¸å½“å‰æ—¶é—´ ----
from datetime import datetime
import pytz

from tools.core import (
    bmi_tool, tdee_tool, skincare_tool,
    mood_to_workout_tool, uv_aqi_advice_tool,
    get_weather_realtime, get_weather_forecast, 
)


# ç”¨ WeatherAPI çš„ tz_id/localtime_epoch æ„é€ â€œåŸå¸‚æœ¬åœ°æ—¶é—´â€ =====
def dt_from_weather(localtime_epoch: Optional[int], tz_id: Optional[str]) -> datetime:
    """
    è¿”å›â€œåŸå¸‚å½“å‰æœ¬åœ°æ—¶é—´â€ã€‚ä¼˜å…ˆç”¨æœ¬æœº UTC -> åŸå¸‚æ—¶åŒºçš„å®æ—¶æ—¶é—´ï¼›
    ä»…å½“ WeatherAPI çš„ localtime_epoch ä¸å½“å‰æ—¶é—´ç›¸å·®ä¸è¶…è¿‡2åˆ†é’Ÿæ—¶ï¼Œæ‰é‡‡ç”¨ API æ—¶é—´ã€‚
    è¿™æ ·å¯æ¶ˆé™¤ WeatherAPI åˆ·æ–°/ç¼“å­˜å¸¦æ¥çš„å‡ åˆ†é’Ÿåå·®ã€‚
    """
    try:
        tz = pytz.timezone(tz_id or "Australia/Sydney")
    except Exception:
        tz = pytz.timezone("Australia/Sydney")

    # ä»¥æœ¬æœºUTCæ—¶é—´ä¸ºå‡†ï¼Œè½¬æ¢åˆ°åŸå¸‚æ—¶åŒºï¼ˆå®æ—¶æ—¶é’Ÿï¼‰
    now_tz = datetime.now(pytz.utc).astimezone(tz)

    # å¦‚æœ API ç»™äº† localtime_epochï¼Œä¸”ä¸ now_tz ç›¸å·®ä¸è¶…è¿‡ 120 ç§’ï¼Œåˆ™é‡‡ç”¨ API æ—¶é—´
    if isinstance(localtime_epoch, (int, float)):
        try:
            api_dt = datetime.fromtimestamp(localtime_epoch, tz)
            if abs((now_tz - api_dt).total_seconds()) <= 120:
                return api_dt
        except Exception:
            pass

    # é»˜è®¤è¿”å›å®æ—¶æ¢ç®—çš„æ—¶åˆ»
    return now_tz

# ===== OpenAI(å…¼å®¹ DashScope) =====
client = OpenAI(
    api_key=os.getenv("DASHSCOPE_API_KEY"),
    base_url=os.getenv("BASE_URL", "https://dashscope-intl.aliyuncs.com/compatible-mode/v1"),
)
MODEL = os.getenv("MODEL_NAME", "qwen-plus")
CHAT = client.with_options(timeout=120.0, max_retries=2) 

# ===== Profile æŒä¹…åŒ–ä¸æ£€ç´¢å™¨ =====
from graph.retriever import ChunkedSemanticRetriever as ChunkedTfidfRetriever
from memory.store import ProfileStore

# ===== AgentState =====
class AgentState(MessagesState):
    route: Optional[str]
    sub_intent: Optional[str]
    retrieved: Optional[List[dict]]
    tool_outputs: Optional[List[dict]]
    need_clarify: Optional[Dict]
    profile: Optional[Dict]
    days_requested: Optional[int] = None
    start_offset: Optional[int] = None


PROFILE = ProfileStore("memory/profile.json")

def _last_text(state: AgentState) -> str:
    msgs = state.get("messages") or []
    if not msgs: return ""
    m = msgs[-1]
    if isinstance(m, dict): return m.get("content", "") or ""
    if hasattr(m, "content"): return m.content or ""
    return str(m)

# ===== è·¯ç”± =====
EMERGENCY = ["èƒ¸ç—›","æ˜å¥","å¤±å»æ„è¯†","å¤§å‡ºè¡€","çŒæ­»","å¤„æ–¹","è¯Šæ–­"]
GREET_WORDS = ["hi","hello","hey","ä½ å¥½","æ‚¨å¥½","å—¨","åœ¨å—","æ—©ä¸Šå¥½","ä¸‹åˆå¥½","æ™šä¸Šå¥½"]

# æ—¶é—´/æ—¥æœŸ/å¯¹æ¯”å…³é”®è¯
TIME_KWS = ["æ—¶é—´","å‡ ç‚¹","æ—¥æœŸ","ä»Šå¤©","ä»Šæ—¥","ç°åœ¨","ä»Šå¤©å‡ å·","ç°åœ¨çš„æ—¶é—´","ç°åœ¨å‡ ç‚¹","now","time","date","today"]
ADVICE_BLOCKERS = ["å»ºè®®","å‡ºè¡Œ","ç©¿è¡£","è£…å¤‡","é€‚ä¸é€‚åˆ","èƒ½ä¸èƒ½","å®‰æ’","è®¡åˆ’","æ˜¯å¦é€‚åˆ","æ¨è"]  # NEW
# ç”¨æˆ·æ˜¯å¦éœ€è¦â€œå»ºè®®/å‡ºè¡Œ/æ¨èâ€ç­‰ï¼ˆç”¨äºæ§åˆ¶æ˜¯å¦è¿½åŠ åˆ†æï¼‰
ADVICE_KWS = [
    "å»ºè®®","å‡ºè¡Œ","ç©¿è¡£","è£…å¤‡","é€‚ä¸é€‚åˆ","èƒ½ä¸èƒ½","å®‰æ’","è®¡åˆ’","æ˜¯å¦é€‚åˆ","æ¨è",
    "advice","advise","suggest","suggestion","plan","itinerary"
]

def _wants_advice(text: str) -> bool:
    t = (text or "").lower()
    return any(k in text for k in ADVICE_KWS) or ("advice" in t) or ("suggest" in t)

def _is_blank(text: str) -> bool:
    return not (text or "").strip()

NOW_TODAY_KWS_ZH = ["ç°åœ¨","æ­¤åˆ»","ä»Šå¤©","ä»Šæ—¥","å½“å‰"]
NOW_TODAY_KWS_EN = ["now","today","current"]


# é¢„æŠ¥æ„å›¾å…³é”®è¯
FORECAST_KWS = [
    "é¢„æŠ¥","é¢„æ¸¬","é¢„æµ‹","æœªæ¥","æ¥ä¸‹æ¥","è¿™å‘¨","æœ¬å‘¨","ä¸‹å‘¨","å‘¨æœ«","ä¸€å‘¨","1å‘¨","ä¸€æ˜ŸæœŸ","ä¸€ç¤¼æ‹œ",
    "æ˜å¤©","æ˜æ—¥","ç¿Œæ—¥","æ¬¡æ—¥","åå¤©","åæ—¥","ä¸¤å‘¨","åå››å¤©","14å¤©","14 æ—¥",
    "ä¸ƒå¤©","7å¤©","10å¤©","é•¿æœŸ","å¤šæ—¥","è¶‹åŠ¿",
    "forecast","next","coming","this week","next week","tomorrow","weekend","two weeks","14-day","14d","7-day","10-day","one week"
]

def _is_time_only_query(text: str) -> bool:
    t = text.lower()
    hit_time = any(k in text for k in TIME_KWS)
    hit_advice = any(k in text for k in ADVICE_BLOCKERS) or ("advice" in t) or ("suggest" in t)
    return hit_time and not hit_advice  # åªæœ‰çº¯æ—¶é—´æ‰èµ° time_only

COMPARE_KWS = ["å¯¹æ¯”","æ¯”è¾ƒ","æ¯”ä¸€æ¯”","compare","vs","å¯¹ç…§"]

TOOLS_KEYWORDS = {
    "bmi":"bmi","tdee":"tdee","çƒ­é‡":"tdee","å¡è·¯é‡Œ":"tdee",
    "æŠ¤è‚¤":"skin","aé†‡":"skin","ç»´c":"skin","vc":"skin","çƒŸé…°èƒº":"skin","æœé…¸":"skin","æ°´æ¨é…¸":"skin","æ•æ„Ÿè‚Œ":"skin"
}

# åŠ å…¥æ—¶é—´/æ—¥æœŸ/å¯¹æ¯”ç­‰å…³é”®è¯
INTENT_MAP = {
    "environment": ["å¤©æ°”","ç´«å¤–çº¿","uv","ç©ºæ°”è´¨é‡","æˆ·å¤–","å…¬å›­","æ­¥é“","æµ·è¾¹","æµ·æ»©","beach","è‡ªç„¶ç–—æ„ˆ","æ£®æ—", *TIME_KWS, *COMPARE_KWS],  # CHANGED
    "fitness": ["è®­ç»ƒ","å¥èº«","åŠ›é‡","hiit","è·‘æ­¥","æ‹‰ä¼¸","å¢è‚Œ","å‡è„‚","è¿åŠ¨"],
    "nutrition": ["é¥®é£Ÿ","é£Ÿè°±","é«˜è›‹ç™½","ä½gi","æŠ—ç‚","ä¹°èœ","woolworths","coles","è¥å…»"],
    "mind": ["ç„¦è™‘","ä½è½","æƒ…ç»ª","å†¥æƒ³","å‘¼å¸","æ‹–å»¶","å‹åŠ›","æ­£å¿µ","ç¡ä¸å¥½","å¤±çœ ","æƒ…æ„Ÿ"],
    "medical": ["ä½“æ£€","åŒ–éªŒ","è¡€ç³–","èƒ†å›ºé†‡","bmiæŒ‡æ ‡","gp","ç†ç–—","åº·å¤","ç–¼ç—›","åŒ»å­¦è§£é‡Š"],
}

def _detect_mood(text: str) -> str:
    t = text.lower()
    if any(k in t for k in ["ç„¦è™‘","anxious","ç´§å¼ ","å¿ƒæ…Œ"]): return "anxious"
    if any(k in t for k in ["ä½è½","æ²®ä¸§","æ²¡åŠ²","æ— åŠ›","down"]): return "low"
    if any(k in t for k in ["å…´å¥‹","å—¨","æ¿€åŠ¨","excited"]): return "excited"
    return "neutral"

# ===== åŸå¸‚è¯†åˆ«=====
CITY_RULES = [  # NEW
    ({"en": [r"\bsydney\b"], "zh": ["æ‚‰å°¼"]}, "Sydney,AU"),
    ({"en": [r"\bmelbourne\b"], "zh": ["å¢¨å°”æœ¬","å¢¨å¸‚"]}, "Melbourne,AU"),
    ({"en": [r"\bbrisbane\b"], "zh": ["å¸ƒé‡Œæ–¯ç­"]}, "Brisbane,AU"),
    ({"en": [r"\bcanberra\b"], "zh": ["å ªåŸ¹æ‹‰"]}, "Canberra,AU"),
    ({"en": [r"\bperth\b"], "zh": ["ç€æ–¯"]}, "Perth,AU"),
    ({"en": [r"\badelaide\b"], "zh": ["é˜¿å¾·è±å¾·","é˜¿å¾·"]}, "Adelaide,AU"),
    ({"en": [r"\bhobart\b"], "zh": ["éœå·´ç‰¹"]}, "Hobart,AU"),
    ({"en": [r"\bgold\s*coast\b"], "zh": ["é»„é‡‘æµ·å²¸"]}, "Gold Coast,AU"),
    ({"en": [r"\bnewcastle\b"], "zh": ["çº½å¡æ–¯å°”","çº½å¡"]}, "Newcastle,AU"),
    ({"en": [r"\bdarwin\b"], "zh": ["è¾¾å°”æ–‡"]}, "Darwin,AU"),
    ({"en": [r"\bcairns\b"], "zh": ["å‡¯æ©æ–¯"]}, "Cairns,AU"),
    ({"en": [r"\bsunshine\s*coast\b"], "zh": ["é˜³å…‰æµ·å²¸"]}, "Sunshine Coast,AU"),
    ({"en": [r"\bgeelong\b"], "zh": ["å‰æœ—"]}, "Geelong,AU"),
]

def _detect_au_cities(q: str) -> List[str]:
    """
   æ”¯æŒè¯†åˆ«å¤šä¸ªæ¾³æ´²åŸå¸‚ï¼ˆåŒ…æ‹¬â€œæ‚‰å°¼å’Œå¢¨å°”æœ¬å¯¹æ¯”å¤©æ°”â€ï¼‰
    - è‡ªåŠ¨åˆ†å‰²â€œå’Œã€ä¸ã€åŠã€ã€ã€andâ€ç­‰è¿æ¥è¯
    - ä¿ç•™å¤šä¸ªåŒ¹é…ç»“æœå¹¶å»é‡
    """
    text_en = (q or "").lower()
    text_zh = q or ""
    out = []

    # å°è¯•å…ˆåˆ†å‰²å¥å­ï¼Œæå–å‡ºå„éƒ¨åˆ† 
    # æ¯”å¦‚ â€œæ‚‰å°¼å’Œå¢¨å°”æœ¬ä»Šå¤©å¯¹æ¯”ä¸€ä¸‹å¤©æ°”â€å˜æˆ ["æ‚‰å°¼", "å¢¨å°”æœ¬ä»Šå¤©å¯¹æ¯”ä¸€ä¸‹å¤©æ°”"]
    parts = re.split(r"[å’Œã€ä¸åŠ,ï¼Œ\s]+|and", text_zh)
    parts = [p.strip() for p in parts if p.strip()]

    # é’ˆå¯¹æ¯ä¸€éƒ¨åˆ†æ‰§è¡ŒåŸå¸‚åŒ¹é… 
    for part in parts:
        for rule, city in CITY_RULES:
            matched_en = any(re.search(pat, part.lower()) for pat in rule.get("en", []))
            matched_zh = any(word in part for word in rule.get("zh", []))
            if matched_en or matched_zh:
                out.append(city)

    # å»é‡ä½†ä¿ç•™é¡ºåº
    out = list(dict.fromkeys(out))

    # è‹¥æ²¡è¯†åˆ«åˆ°ä»»ä½•åŸå¸‚ï¼Œå…œåº•ä¸ºæ‚‰å°¼
    if not out:
        raw = text_zh.strip()
        out = [raw] if raw else ["Sydney,AU"]

    return out


# NLP + LLM æ—¶é—´è·¨åº¦è§£æ 
def _parse_time_span_nlp(text: str) -> int:
    """
    NLPå±‚ï¼šè§£æè‡ªç„¶è¯­è¨€ä¸­çš„æ—¶é—´èŒƒå›´ â†’ è¿”å›å¤©æ•°ï¼ˆ0~14ï¼‰
    """
    t = text.lower()

    # æ˜ç¡®å…³é”®è¯ä¼˜å…ˆåŒ¹é…
    if "ä»Šå¤©" in t or "ä»Šæ—¥" in t or "today" in t:
        return 0
    if any(k in t for k in ["æ˜å¤©", "æ˜æ—¥", "ç¿Œæ—¥", "æ¬¡æ—¥", "tomorrow"]):
        return 1
    if any(k in t for k in ["åå¤©", "åæ—¥", "day after tomorrow"]):
        return 2
    if "å¤§åå¤©" in t:
        return 3
    if any(k in t for k in ["è¿™å‘¨","æœ¬å‘¨","ä¸‹å‘¨","this week","next week","ä¸ƒå¤©","7å¤©"]):
        return 7
    if any(k in t for k in ["ä¸¤å‘¨","14å¤©","åå››å¤©","two weeks","14 days"]):
        return 14
    if any(k in t for k in ["ä¸€å‘¨","1å‘¨","ä¸€æ˜ŸæœŸ","ä¸€ç¤¼æ‹œ","one week"]):
        return 7

    # ä»»æ„æ•°å­— + â€œå¤©/æ—¥/daysâ€
    m = re.search(r"(\d+)\s*(å¤©|æ—¥|days?)", t)
    if m:
        d = int(m.group(1))
        return min(max(d, 1), 14)

    # æ¨¡ç³Šè¡¨è¾¾
    if "æœªæ¥" in t or "æ¥ä¸‹æ¥" in t:
        return 3

    return 3



def _parse_time_span_llm(text: str) -> int:
    """
    LLMå±‚ï¼šå½“NLPæ— æ³•è§£ææˆ–ç”¨æˆ·è¡¨è¿°æ¨¡ç³Šæ—¶è°ƒç”¨å°æ¨¡å‹è¯­ä¹‰åˆ¤æ–­
    è¿”å›å¤©æ•°ï¼ˆ1/3/7/14ï¼‰
    """
    try:
        mini = OpenAI(api_key=os.getenv("DASHSCOPE_API_KEY"))
        resp = mini.chat.completions.create(
            model="qwen-turbo",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæ—¶é—´è§£æåŠ©æ‰‹ï¼Œè¯·æ ¹æ®å¥å­åˆ¤æ–­ç”¨æˆ·æƒ³æŸ¥è¯¢å‡ å¤©çš„å¤©æ°”ï¼Œè¿”å›çº¯æ•°å­—ï¼ˆ0,1,2,3,7,14ï¼‰"},
                {"role": "user", "content": text}
            ],
            temperature=0
        )
        ans = re.findall(r"\d+", resp.choices[0].message.content)
        if ans:
            days = int(ans[0])
            return min(max(days, 0), 14)
        return _parse_time_span_nlp(text)
    except Exception:
        return _parse_time_span_nlp(text)

def _explicit_day_offset(text: str) -> int:
    """è¿”å›èµ·å§‹åç§»ï¼ˆ0=ä»Šå¤©,1=æ˜å¤©/æ˜æ—¥,2=åå¤©/åæ—¥,3=å¤§åå¤©ï¼‰"""
    t = (text or "").lower()
    if any(k in t for k in ["æ˜å¤©", "æ˜æ—¥", "ç¿Œæ—¥", "æ¬¡æ—¥", "tomorrow"]):
        return 1
    if any(k in t for k in ["åå¤©", "åæ—¥", "day after tomorrow"]):
        return 2
    if "å¤§åå¤©" in t:
        return 3
    if any(k in t for k in ["ä»Šå¤©", "ä»Šæ—¥", "today"]):
        return 0
    return 0

def _offset_to_next_week_start(tz_id: str = "Australia/Sydney") -> int:
    """
    è®¡ç®—ä»â€œä»Šå¤©â€åˆ°â€œä¸‹å‘¨ä¸€â€çš„å¤©æ•°åç§»ï¼ˆä»Šå¤©æ˜¯å‘¨ä¸€åˆ™è¿”å› 7ï¼‰ã€‚
    ä»…ç”¨äºâ€œä¸‹å‘¨â€è¯­ä¹‰çš„èµ·å§‹æ—¥å®šä½ã€‚
    """
    try:
        tz = pytz.timezone(tz_id)
    except Exception:
        tz = pytz.timezone("Australia/Sydney")
    now = datetime.now(tz)
    # Python: Monday=0 ... Sunday=6
    days_until_next_monday = (7 - now.weekday()) % 7
    return days_until_next_monday or 7

def router_node(state: AgentState):
    """
    æ™ºèƒ½è·¯ç”±èŠ‚ç‚¹ï¼š
    - ä¼˜å…ˆè¯†åˆ«ï¼šæ—¶é—´æŸ¥è¯¢ã€åŸå¸‚å¯¹æ¯”ã€ç´§æ€¥/å·¥å…·ç±»
    - å…¶æ¬¡è¯†åˆ«ï¼šå„é¢†åŸŸæ„å›¾ï¼ˆfitness / nutrition / environment / mind / medicalï¼‰
    - å¯¹ environment å†ç»†åˆ†ï¼štoday / forecast_n / compare / time_only
    """
    text = _last_text(state)
    low = text.lower()
    state["profile"] = PROFILE.load()

    # ---------- ç©ºè¾“å…¥ï¼šè¿›å…¥ idleï¼Œä¸äº§ç”Ÿä»»ä½•å›å¤ ----------
    if _is_blank(text):
        state["route"] = "idle"
        return state

    # ---------- é€šç”¨é¢„å¤„ç† ----------
    cities = _detect_au_cities(text)
    state["sub_intent"] = None

    # ---------- é—®å€™ä¼˜å…ˆï¼šè¿›å…¥ greetï¼ˆè‡ªæˆ‘ä»‹ç»+èƒ½åšä»€ä¹ˆï¼‰ ----------
    if any(w in low for w in GREET_WORDS):
        state["route"] = "greet"
        return state
    
    # ---------- è·¨é¢†åŸŸé«˜ä¼˜å…ˆçº§ ----------
    # å…ˆåˆ¤æ–­ä¸¤åŸå¯¹æ¯”
    if any(k in text for k in COMPARE_KWS) and len(cities) >= 2:
        # å¦‚æœåŒæ—¶åŒ…å«â€œæœªæ¥/æ˜å¤©/åå¤©/ä¸‹å‘¨/next week/å‘¨æœ«â€ç­‰ â†’ èµ°å¤šåŸ forecast å¯¹æ¯”
        if any(k in low for k in FORECAST_KWS) or any(w in text for w in ["æ˜å¤©","æ˜æ—¥","ç¿Œæ—¥","æ¬¡æ—¥","åå¤©","åæ—¥","å¤§åå¤©","æœªæ¥","å‘¨æœ«","weekend","days"]):
            days = _parse_time_span_nlp(text)
            if days not in [0,1,2,3,7,14]:
                days = _parse_time_span_llm(text)

            # â€œä¸‹å‘¨/next weekâ€â†’ ä»ä¸‹å‘¨ä¸€å¼€å§‹çš„ 7 å¤©çª—å£
            if ("ä¸‹å‘¨" in text) or ("next week" in low):
                days = 7
                # ä¹Ÿå¯ç”¨ç¬¬ä¸€ä¸ªåŸå¸‚çš„ tz æ¥æ›´ç²¾ç»†ï¼štz_id = get_weather_realtime(cities[0]).get("tz_id") or "Australia/Sydney"
                offset = _offset_to_next_week_start("Australia/Sydney")
            else:
                offset = _explicit_day_offset(text)

            state["route"] = "environment"
            state["days_requested"] = days
            state["start_offset"] = offset

            if days == 0:
                state["sub_intent"] = "today"
            elif days <= 1:
                state["sub_intent"] = "forecast_1"
            elif days <= 3:
                state["sub_intent"] = "forecast_3"
            elif days <= 7:
                state["sub_intent"] = "forecast_7"
            else:
                state["sub_intent"] = "forecast_14"
            return state

        # å¦åˆ™ï¼šçº¯â€œä»Šæ—¥å®å†µå¯¹æ¯”â€
        state["route"] = "environment"
        state["sub_intent"] = "compare"
        return state

    # åªé—®æ—¶é—´ï¼ˆè‹¥å‘½ä¸­ compare æˆ–å¤šåŸåˆ™ä¸èµ° time_onlyï¼‰
    if _is_time_only_query(text) and not any(k in text for k in COMPARE_KWS) and len(cities) < 2:
        state["route"] = "environment"
        state["sub_intent"] = "time_only"
        return state

    #å®æ—¶å¤©æ°”ï¼ˆå«â€œç°åœ¨â€â€œä»Šå¤©/ä»Šæ—¥/todayâ€ï¼‰
    if any(w in text for w in ["ç°åœ¨","æ­¤åˆ»","today","ä»Šå¤©","ä»Šæ—¥","å½“å‰"]):
        state["route"] = "environment"
        state["sub_intent"] = "today"
        return state

    # å·¥å…· / å®‰å…¨ / é—®å€™ 
    if any(w in text for w in EMERGENCY):
        state["route"] = "safety"
        return state
    for k, v in TOOLS_KEYWORDS.items():
        if k in low:
            state["route"] = v
            return state

    # ä¸‰çº§ï¼šæ„å›¾è¯†åˆ« 
    for intent, kws in INTENT_MAP.items():
        if any(k in low for k in kws):
            state["route"] = intent

            # ---------- ç¯å¢ƒé¢†åŸŸç»†åˆ† ----------
            if intent == "environment":
                # æœªæ¥é¢„æŠ¥ï¼ˆåŠ¨æ€å¤©æ•°ï¼‰
                if any(k in low for k in FORECAST_KWS) or any(w in text for w in ["æ˜å¤©","æ˜æ—¥","ç¿Œæ—¥","æ¬¡æ—¥","åå¤©","åæ—¥","å¤§åå¤©","æœªæ¥","days"]):
                    days = _parse_time_span_nlp(text)
                    if days not in [0,1,2,3,7,14]:
                        days = _parse_time_span_llm(text)
                    # æ–°å¢ï¼šæ˜¾å¼åç§»ï¼ˆæ˜å¤©/åå¤©/å¤§åå¤©ï¼‰
                    offset = _explicit_day_offset(text)
                    state["days_requested"] = days
                    state["start_offset"] = offset     

                    if days == 0:
                        state["sub_intent"] = "today"
                    elif days <= 1:
                        state["sub_intent"] = "forecast_1"
                    elif days <= 3:
                        state["sub_intent"] = "forecast_3"
                    elif days <= 7:
                        state["sub_intent"] = "forecast_7"
                    else:
                        state["sub_intent"] = "forecast_14"
                    return state

                # å…¶å®ƒå¤©æ°”è¯¢é—®ï¼ˆæœªæ forecastï¼‰å°±æ˜¯ today é»˜è®¤
                state["sub_intent"] = "today"
                return state
            
            return state
        
    # éƒ½æ²¡å‘½ä¸­æ—¶å›é€€åˆ° RAG
    state["route"] = "rag"
    return state

# ====== Pydantic è¾“å…¥ï¼ˆBMI/TDEE/Skinï¼‰ ======
class BMIInput(BaseModel):
    height_cm: float
    weight_kg: float

class TDEEInput(BaseModel):
    sex: str
    age: int
    height_cm: float
    weight_kg: float
    activity_level: str

class SkinInput(BaseModel):
    skin_type: str
    concerns: str
    actives_in_use: str

# ====== è§£æ + å·¥å…·èŠ‚ç‚¹ï¼ˆBMI/TDEE/Skinï¼‰======
def _parse_numbers(text: str) -> List[float]:
    return list(map(float, re.findall(r"\d+\.?\d*", text)))

def _parse_bmi(text: str, profile: Dict) -> Tuple[Optional[BMIInput], List[str]]:
    nums = _parse_numbers(text)
    height = weight = None
    if len(nums) >= 2:
        h_m = re.search(r"(\d+\.?\d*)\s*cm", text.lower())
        w_m = re.search(r"(\d+\.?\d*)\s*kg", text.lower())
        height = float(h_m.group(1)) if h_m else float(nums[0])
        weight = float(w_m.group(1)) if w_m else float(nums[1])
    else:
        height = profile.get("height_cm")
        weight = profile.get("weight_kg")
    missing = []
    if height is None: missing.append("èº«é«˜(cm)")
    if weight is None: missing.append("ä½“é‡(kg)")
    if missing: return None, missing
    return BMIInput(height_cm=height, weight_kg=weight), []

def _parse_tdee(text: str, profile: Dict) -> Tuple[Optional[TDEEInput], List[str]]:
    tlow = text.lower()

    # æ€§åˆ«è§£æ
    sex = None
    if any(x in text for x in ["å¥³","å¥³ç”Ÿ","å¥³æ€§"]) or "female" in tlow or re.search(r"\bf\b", tlow):
        sex = "female"
    elif any(x in text for x in ["ç”·","ç”·ç”Ÿ","ç”·æ€§"]) or "male" in tlow or re.search(r"\bm\b", tlow):
        sex = "male"

    # å…¨éƒ¨æ•°å­—æŠ“å–ï¼ˆä¸å«å•ä½ï¼‰
    nums = _parse_numbers(text)  # ä¾‹å¦‚ "ç”·ï¼Œ38å²ï¼Œèº«é«˜170ï¼Œä½“é‡52" -> [38,170,52]
    nums_remain = nums[:]        # åé¢ä¼šé€æ­¥å‰”é™¤å·²ç”¨åˆ°çš„æ•°å­—

    # å…ˆç”¨æ˜¾å¼æ­£åˆ™æŠ“â€œæœ‰æ ‡ç­¾/æœ‰å•ä½â€çš„å€¼
    age = None
    height = None
    weight = None

    age_m = re.search(r"(\d+)\s*å²", text)
    if age_m:
        age = int(age_m.group(1))
        # ä»å‰©ä½™æ•°å­—é‡Œå‰”é™¤è¿™ä¸ªå¹´é¾„
        try:
            nums_remain.remove(float(age))
        except Exception:
            pass

    # å¸¦å•ä½
    h_cm = re.search(r"(\d+\.?\d*)\s*cm", tlow)
    w_kg = re.search(r"(\d+\.?\d*)\s*kg", tlow)
    if h_cm:
        height = float(h_cm.group(1))
        try:
            nums_remain.remove(float(height))
        except Exception:
            pass
    if w_kg:
        weight = float(w_kg.group(1))
        try:
            nums_remain.remove(float(weight))
        except Exception:
            pass

    # æ²¡å†™å•ä½æ—¶ï¼šæŒ‰ä¸­æ–‡æ ‡ç­¾æŠ“å–
    if height is None:
        h2 = re.search(r"(èº«é«˜|é«˜)\s*(\d+\.?\d*)", text)
        if h2:
            height = float(h2.group(2))
            try:
                nums_remain.remove(float(height))
            except Exception:
                pass
    if weight is None:
        w2 = re.search(r"(ä½“é‡|é‡)\s*(\d+\.?\d*)", text)
        if w2:
            weight = float(w2.group(2))
            try:
                nums_remain.remove(float(weight))
            except Exception:
                pass

    # å…œåº•ï¼šè¿˜ç¼ºå°±ä»â€œå‰©ä½™æ•°å­—â€é‡ŒæŒ‰å¸¸è¯†è§„åˆ™å¡«
    def pick_height_weight_from_remaining(arr):
        h, w = None, None
        # å…ˆæŒ‰èŒƒå›´çŒœ
        for v in list(arr):
            if h is None and 120 <= v <= 230:
                h = float(v); arr.remove(v); break
        for v in list(arr):
            if w is None and 30 <= v <= 200:
                w = float(v); arr.remove(v); break
        return h, w

    if height is None or weight is None:
        h_guess, w_guess = pick_height_weight_from_remaining(nums_remain)
        if height is None and h_guess is not None:
            height = h_guess
        if weight is None and w_guess is not None:
            weight = w_guess

    # è‹¥ä»æœ‰ç©ºï¼Œæœ€åæŒ‰â€œæ–‡æœ¬å‡ºç°é¡ºåºâ€å…œåº•
    if height is None and nums_remain:
        height = float(nums_remain.pop(0))
    if weight is None and nums_remain:
        weight = float(nums_remain.pop(0))

    # å¸¸è¯†æ€§çº é”™ï¼šè‹¥ height<100 ä¸” weight>100ï¼Œæå¯èƒ½å†™åäº† â†’ äº¤æ¢
    if (height is not None and weight is not None) and (height < 100 and weight > 100):
        height, weight = weight, height

    # æ´»åŠ¨æ°´å¹³
    level_map = {
        "ä¹…å":"sedentary","ä¸æ€ä¹ˆåŠ¨":"sedentary","sedentary":"sedentary",
        "è½»åº¦":"light","light":"light","ä¸­ç­‰":"moderate","é€‚ä¸­":"moderate","moderate":"moderate",
        "æ´»è·ƒ":"active","è¿åŠ¨è¾ƒå¤š":"active","active":"active","è¿åŠ¨å‘˜":"athlete","é«˜å¼ºåº¦":"athlete","athlete":"athlete"
    }
    activity_level = None
    for k,v in level_map.items():
        if k in tlow:
            activity_level = v; break
    if not activity_level:
        activity_level = profile.get("activity_level")

    # ç”»åƒå…œåº•
    if sex is None:   sex   = profile.get("sex")
    if age is None:   age   = profile.get("age")
    if height is None:height= profile.get("height_cm")
    if weight is None:weight= profile.get("weight_kg")

    # ç¼ºå¤±æ£€æŸ¥
    missing = []
    if not sex: missing.append("æ€§åˆ«")
    if age is None: missing.append("å¹´é¾„")
    if height is None: missing.append("èº«é«˜(cm)")
    if weight is None: missing.append("ä½“é‡(kg)")
    if not activity_level: missing.append("æ´»åŠ¨æ°´å¹³(ä¹…å/è½»åº¦/ä¸­ç­‰/æ´»è·ƒ/è¿åŠ¨å‘˜)")
    if missing:
        return None, missing

    return TDEEInput(
        sex=sex,
        age=int(age),
        height_cm=float(height),
        weight_kg=float(weight),
        activity_level=activity_level
    ), []

def _parse_skin(text: str, profile: Dict) -> Tuple[Optional[SkinInput], List[str]]:
    tlow = text.lower()
    skin_map = {"å¤§å¹²çš®":"dry","å¹²":"dry","æ²¹":"oily","å‡ºæ²¹":"oily","æ··åˆ":"oily","æ•":"sensitive","æ•æ„Ÿ":"sensitive"}
    skin_type = None
    for k,v in skin_map.items():
        if k in tlow: skin_type = v; break
    if not skin_type: skin_type = profile.get("skin_type")
    active_alias = {
        "aé†‡":"retinol","è§†é»„é†‡":"retinol",
        "æœé…¸":"aha_bha","æ°´æ¨é…¸":"aha_bha","aha":"aha_bha","bha":"aha_bha",
        "vc":"vitc","ç»´c":"vitc","çƒŸé…°èƒº":"niacinamide",
        "å£¬äºŒé…¸":"aza","è¿‡æ°§åŒ–è‹¯ç”²é…°":"benzoyl_peroxide","bpo":"benzoyl_peroxide"
    }
    found = set()
    for k,v in active_alias.items():
        if k in tlow: found.add(v)
    actives = list(found) or (profile.get("actives_in_use", "").split(",") if profile.get("actives_in_use") else [])
    actives = [a.strip() for a in actives if a and a.strip()]
    concerns = []
    for kw in ["ç—˜","ç²‰åˆº","é—­å£","ç¾ç™½","æ·¡æ–‘","æŠ—è€","ä¿®æŠ¤","è„±çš®","å¹²ç‡¥"]:
        if kw in text: concerns.append(kw)
    concerns = "ã€".join(concerns) or profile.get("concerns", "åŸºç¡€æŠ¤ç†")
    missing = []
    if not skin_type: missing.append("è‚¤è´¨")
    if missing: return None, missing
    return SkinInput(skin_type=skin_type, concerns=concerns, actives_in_use=", ".join(actives)), []

def _tdee_advice_fallback(parsed: "TDEEInput", res: Dict) -> str:
    h_m = parsed.height_cm / 100.0
    bmi = round(parsed.weight_kg / (h_m * h_m), 1)
    tdee = int(res.get("tdee", 0))
    goal = "å‡è„‚" if bmi >= 27 else ("ä½“æ€é‡å¡‘" if 23 <= bmi < 27 else "å¢è‚Œ/åŠ›é‡æå‡")
    # çƒ­é‡å»ºè®®
    if goal == "å‡è„‚":
        kcal = max(tdee - 300, tdee - int(0.15 * tdee))
        kcal_line = f"æ¯æ—¥çƒ­é‡å»ºè®®ï¼šçº¦ **{kcal} kcal**ï¼ˆè¾ƒTDEE -300 ~ -15%ï¼‰"
    elif goal == "ä½“æ€é‡å¡‘":
        kcal_line = f"æ¯æ—¥çƒ­é‡å»ºè®®ï¼šâ‰ˆ **{tdee} kcal**ï¼ˆå›´ç»•TDEEå¾®è°ƒ Â±100ï¼‰"
    else:
        kcal_line = f"æ¯æ—¥çƒ­é‡å»ºè®®ï¼šâ‰ˆ **{tdee + 300} kcal**ï¼ˆè¾ƒTDEE +300ï¼‰"

    # å‘¨è®¡åˆ’ï¼ˆæŒ‰ä¹…åèµ·æ­¥ï¼‰
    plan = (
        "**ä¸€å‘¨è®­ç»ƒæ¨¡æ¿ï¼ˆä¹…åèµ·æ­¥ï¼‰**\n"
        "- åŠ›é‡ x3ï¼šå…¨èº«A/Bäº¤æ›¿ï¼ˆæ·±è¹²/ç¡¬æ‹‰/å§æ¨æˆ–ä¿¯å§æ’‘/åˆ’èˆ¹/æ¨ä¸¾ï¼‰ï¼Œæ¯ç»ƒä¹  3â€“4 ç»„ Ã— 6â€“12 æ¬¡ï¼ŒRPE 7â€“8ã€‚\n"
        "- æœ‰æ°§ x2ï¼šLISS 30â€“40 åˆ†é’Ÿï¼ˆå¿«èµ°/æ¤­åœ†/éª‘è¡Œï¼‰ï¼Œè‹¥ä½“èƒ½å¥½å¯åŠ å…¥ 1 æ¬¡ 10Ã—(1â€²å¿«+1â€²æ…¢) çš„é—´æ­‡ã€‚\n"
        "- NEATï¼š**æ—¥æ­¥æ•° 7000â€“9000**ï¼Œåˆ†æ•£åˆ°ç™½å¤©ï¼ˆç•ªèŒ„é’Ÿæ¯ 50 åˆ†é’Ÿèµ·èº«èµ° 3â€“5 åˆ†é’Ÿï¼‰ã€‚\n"
    )

    # è¿›é˜¶ä¸æ¢å¤
    prog = (
        "**è¿›é˜¶ä¸æ¢å¤**\n"
        "- æ¸è¿›è¶…è´Ÿè·ï¼šå½“æŸåŠ¨ä½œ 3 ç»„éƒ½èƒ½è½»æ¾å®Œæˆä¸Šé™æ¬¡æ•°ï¼Œä¸‹æ¬¡åŠ  **2.5â€“5kg** æˆ–å¢åŠ  1â€“2 æ¬¡é‡å¤ã€‚\n"
        "- çµæ´»æ€§ï¼šè®­ç»ƒå‰ 5 åˆ†é’ŸåŠ¨æ€çƒ­èº«ï¼ˆé«‹/è‚©/è¸ï¼‰ï¼Œè®­ç»ƒå 5 åˆ†é’Ÿé™æ€æ‹‰ä¼¸ï¼ˆè…˜ç»³è‚Œã€å°è…¿ã€èƒ¸èƒŒï¼‰ã€‚\n"
        "- ç¡çœ ï¼š**7â€“9 å°æ—¶**ï¼›è›‹ç™½ 1.6â€“2.2 g/kgï¼›æ°´ï¼š**ä½“é‡Ã—35ml**/æ—¥ï¼Œè®­ç»ƒæ—¥ç•¥å¢ã€‚\n"
        "- ä¼¤ç—›é¢„é˜²ï¼šç–¼ç—›>24hæœªç¼“è§£æˆ–åŠ é‡â†’å‡é‡/å°±åŒ»ï¼›æ ¸å¿ƒç¨³å®šä¸é«‹å‘¨æ¿€æ´»æ¯æ¬¡è®­ç»ƒ 5â€“8 åˆ†é’Ÿã€‚\n"
    )

    # ç¤ºä¾‹æ—¥ç¨‹
    sched = (
        "**å‚è€ƒæ—¥ç¨‹**\n"
        "- å‘¨ä¸€ï¼šåŠ›é‡Aï¼ˆæ·±è¹²/å§æ¨/åˆ’èˆ¹ï¼‰+ æ ¸å¿ƒ 8â€²\n"
        "- å‘¨äºŒï¼šLISS 35â€² + ä¼¸å±• 5â€²\n"
        "- å‘¨ä¸‰ï¼šä¼‘æ¯/æ­¥è¡Œ 30â€²\n"
        "- å‘¨å››ï¼šåŠ›é‡Bï¼ˆç¡¬æ‹‰/æ¨ä¸¾/å¼•ä½“æˆ–ä¸‹æ‹‰ï¼‰+ æ ¸å¿ƒ 8â€²\n"
        "- å‘¨äº”ï¼šLISS 30â€²ï¼ˆå¯åš10Ã—(1â€²å¿«+1â€²æ…¢)ï¼‰\n"
        "- å‘¨å…­ï¼šåŠ›é‡Aï¼ˆé™ä½ 5â€“10% è´Ÿé‡ï¼Œç»ƒæŠ€æœ¯ï¼‰\n"
        "- å‘¨æ—¥ï¼šä¼‘æ¯/æˆ·å¤–è½»æ¾èµ° 30â€“60â€²\n"
    )

    return (
        f"### ä¸ªæ€§åŒ–è®­ç»ƒä¸è¥å…»å»ºè®®\n"
        f"- ç›®æ ‡å€¾å‘ï¼š**{goal}**ï¼ˆåŸºäº BMI {bmi}ï¼‰\n"
        f"- {kcal_line}\n\n"
        f"{plan}\n{prog}\n{sched}"
        "è‹¥æœ€è¿‘å®Œå…¨ä¸è¿åŠ¨ï¼Œå¯ä» **åŠ›é‡ x2 + LISS x2** èµ·æ­¥ï¼Œ2â€“4 å‘¨åå†åŠ åˆ°ä¸Šè¿°å‘¨é¢‘æ¬¡ã€‚"
    )


def tool_node(state: AgentState):
    """
    å·¥å…·èŠ‚ç‚¹ï¼šè§£æç”¨æˆ·è¾“å…¥ â†’ è°ƒç”¨å¯¹åº”å·¥å…·å‡½æ•° â†’ ç”Ÿæˆç»“æ„åŒ–è¾“å‡º
    é€‚ç”¨ï¼šBMI / TDEE / Skin ä¸‰ç±»
    """
    text = _last_text(state)
    prof = state.get("profile") or {}
    out = []

    # ==== â‘  BMI è®¡ç®— ====
    if state.get("route") == "bmi":
        parsed, missing = _parse_bmi(text, prof)
        if missing:
            state["need_clarify"] = {
                "tool": "bmi",
                "missing": missing,
                "hint": "ç¤ºä¾‹ï¼šèº«é«˜165cm ä½“é‡55kg"
            }
            state["tool_outputs"] = []
            return state

        res = bmi_tool(**parsed.model_dump())
        out.append({
            "tool": "bmi",
            "input": parsed.model_dump(),
            "result": res,
            "assumption": "ä»æ–‡æœ¬/ç”»åƒè§£æ"
        })
        PROFILE.update(height_cm=parsed.height_cm, weight_kg=parsed.weight_kg)
        content = (
            f"**BMI è®¡ç®—ç»“æœ**\n"
            f"- èº«é«˜ï¼š{parsed.height_cm} cm\n"
            f"- ä½“é‡ï¼š{parsed.weight_kg} kg\n"
            f"- BMIï¼š{res['bmi']}\n"
            f"- ä½“é‡åˆ†ç±»ï¼š{res['category']}\n\n"
            f"ğŸ‘‰ æ­£å¸¸èŒƒå›´ä¸º 18.5â€“24ã€‚è‹¥æƒ³ä¼˜åŒ–ä½“å‹ï¼Œå¯ç»“åˆ TDEE è®¡ç®—æ¯æ—¥èƒ½é‡æ¶ˆè€—ã€‚"
        )
        wants = _wants_advice(text)

        final_text = content  # å…ˆé»˜è®¤åªè¾“å‡ºè®¡ç®—ç»“æœ
        if wants:
            # è®¡ç®—å¥åº·ä½“é‡åŒºé—´ï¼ˆä¾¿äºç»™å‡ºè½åœ°ç›®æ ‡ï¼‰
            w_min, w_max = _bmi_weight_range(parsed.height_cm)
            tool_ctx = [{
                "tool": "bmi",
                "input": parsed.model_dump(),
                "result": {**res, "healthy_weight_range": [w_min, w_max]}
            }]
            ctx, srcs = _ctx_and_sources(state, tool_ctx)

            prompt = (
                "åŸºäºä»¥ä¸‹ BMI ç»“æœï¼Œä¸ºç”¨æˆ·ç”Ÿæˆâ€œå¯ç›´æ¥ç…§åšâ€çš„è¿åŠ¨ä¸é¥®é£Ÿå»ºè®®ï¼š\n"
                f"- èº«é«˜ï¼š{parsed.height_cm} cmï¼›ä½“é‡ï¼š{parsed.weight_kg} kgï¼›BMIï¼š{res.get('bmi')}\n"
                f"- ä½“é‡åˆ†ç±»ï¼š{res.get('category')}ï¼›å¥åº·ä½“é‡åŒºé—´ï¼ˆBMI 18.5â€“24ï¼‰ï¼šçº¦ {w_min}â€“{w_max} kg\n\n"
                "è¾“å‡ºè¦æ±‚ï¼š\n"
                "1) ç›®æ ‡ä½“é‡ä¸èŠ‚å¥ï¼ˆæ¯å‘¨0.25â€“0.75 kgæ›´å®‰å…¨ï¼‰ï¼Œå¹¶è¯´æ˜çƒ­é‡æ”¶æ”¯åŸåˆ™\n"
                "2) ä¸€å‘¨è®­ç»ƒæ¨¡æ¿ï¼šåŠ›é‡ï¼ˆéƒ¨ä½/åŠ¨ä½œ/ç»„æ¬¡/RPEï¼‰+ æœ‰æ°§ï¼ˆé¢‘æ¬¡/æ—¶é•¿/å¼ºåº¦ï¼‰+ æ‹‰ä¼¸\n"
                "3) é¥®é£Ÿç»“æ„ï¼šè›‹ç™½/ç¢³æ°´/è„‚è‚ªå»ºè®®ï¼Œç®€å•å¯æ‰§è¡Œçš„é¤ä¾‹ï¼ˆè¶…å¸‚å¯ä¹°åˆ°ï¼‰\n"
                "4) ç”Ÿæ´»æ–¹å¼ï¼šç¡çœ ã€æ­¥æ•°ï¼ˆNEATï¼‰ã€è¡¥æ°´ã€ç”µè§£è´¨ä¸é£é™©æç¤º\n"
                "5) è¦ç‚¹å¼ä¸­æ–‡è¾“å‡ºï¼Œæ•°å€¼æ˜ç¡®ï¼Œå¯ç›´æ¥æ‰§è¡Œ\n"
            )

            fallback_advice = _bmi_advice_fallback(parsed, res, (w_min, w_max))
            advice_text = _safe_llm_answer(prompt, ctx, srcs, fallback_advice)

            final_text = content + "\n\n" + advice_text  # éœ€è¦å»ºè®®æ—¶å†æ‹¼æ¥
        state["messages"].append(AIMessage(content=final_text))

        state["tool_outputs"] = out
        state["need_clarify"] = None
        return state
    
    # ==== â‘¡ TDEE è®¡ç®—ï¼ˆåˆå¹¶ä¸ºä¸€æ¡æ¶ˆæ¯å‘é€ï¼‰ ====
    elif state.get("route") == "tdee":
        parsed, missing = _parse_tdee(text, prof)
        if missing:
            state["need_clarify"] = {
                "tool": "tdee",
                "missing": missing,
                "hint": "ç¤ºä¾‹ï¼šå¥³ 23å² 165cm 55kg ä¸­ç­‰æ´»åŠ¨"
            }
            state["tool_outputs"] = []
            return state

        res = tdee_tool(**parsed.model_dump())
        out.append({
            "tool": "tdee",
            "input": parsed.model_dump(),
            "result": res,
            "assumption": "ä»æ–‡æœ¬/ç”»åƒè§£æ"
        })
        PROFILE.update(**parsed.model_dump())

        content = (
            f"**TDEE è®¡ç®—ç»“æœ**\n"
            f"- æ€§åˆ«ï¼š{parsed.sex}\n"
            f"- å¹´é¾„ï¼š{parsed.age} å²\n"
            f"- èº«é«˜ï¼š{parsed.height_cm} cm\n"
            f"- ä½“é‡ï¼š{parsed.weight_kg} kg\n"
            f"- æ´»åŠ¨æ°´å¹³ï¼š{parsed.activity_level}\n\n"
            f"**ç»“æœï¼š**\n"
            f"- åŸºç¡€ä»£è°¢ (BMR)ï¼š{res['bmr']} kcal\n"
            f"- æ¯æ—¥æ€»æ¶ˆè€— (TDEE)ï¼š{res['tdee']} kcal\n\n"
            f"ğŸ‘‰ è‹¥ç›®æ ‡ä¸ºå‡è„‚ï¼šæ¯æ—¥æ‘„å…¥æ¯” TDEE ä½çº¦ 300 kcalã€‚\n"
            f"ğŸ‘‰ è‹¥ç›®æ ‡ä¸ºå¢è‚Œï¼šæ¯æ—¥æ‘„å…¥æ¯” TDEE é«˜çº¦ 300 kcalã€‚"
        )

        source_note = "ï¼ˆèº«é«˜/ä½“é‡æ¥è‡ªä¸ªäººç”»åƒï¼Œå¦‚éœ€æ›´æ–°è¯·å‘Šè¯‰æˆ‘ï¼‰"
        content = content + "\n" + source_note

        wants = _wants_advice(text)

        advice_text = ""
        if wants:
            tool_ctx = [{"tool": "tdee", "input": parsed.model_dump(), "result": res}]
            ctx, srcs = _ctx_and_sources(state, tool_ctx)
            prompt = (
                "è¯·åŸºäºä»¥ä¸‹ä¸ªäººèµ„æ–™ä¸èƒ½é‡æ¶ˆè€—ï¼Œç”Ÿæˆâ€œ**å¯ç›´æ¥ç…§åš**â€çš„è®­ç»ƒå»ºè®®ï¼š\n"
                f"- æ€§åˆ«ï¼š{parsed.sex}ï¼›å¹´é¾„ï¼š{parsed.age}ï¼›èº«é«˜ï¼š{parsed.height_cm}cmï¼›ä½“é‡ï¼š{parsed.weight_kg}kgï¼›æ´»åŠ¨æ°´å¹³ï¼š{parsed.activity_level}\n"
                f"- TDEEï¼š{int(res.get('tdee',0))} kcalï¼›BMRï¼š{int(res.get('bmr',0))} kcal\n\n"
                "è¾“å‡ºè¦æ±‚ï¼š\n"
                "1) ç›®æ ‡å»ºè®®ï¼ˆå‡è„‚/ä½“æ€é‡å¡‘/å¢è‚Œï¼‰ä¸æ¯æ—¥çƒ­é‡å»ºè®®ï¼ˆç»“åˆTDEEç»™å‡ºæ•°å€¼æˆ–åŒºé—´ï¼‰\n"
                "2) ä¸€å‘¨è®­ç»ƒæ¨¡æ¿ï¼ˆåŠ›é‡/æœ‰æ°§é¢‘æ¬¡ã€åŠ¨ä½œç»„åˆã€ç»„æ¬¡/é‡å¤ã€RPEã€ä¼‘æ¯ï¼‰\n"
                "3) æ¸è¿›è¶…è´Ÿè·è§„åˆ™ã€NEATï¼ˆæ—¥æ­¥æ•°ï¼‰ä¸çµæ´»æ€§/æ‹‰ä¼¸å®‰æ’\n"
                "4) æ¢å¤ä¸ä¼¤ç—›é¢„é˜²è¦ç‚¹ï¼ˆç¡çœ /è¥å…»/ä½•æ—¶å‡é‡æˆ–å°±åŒ»ï¼‰\n"
                "5) ç”¨ä¸­æ–‡è¦ç‚¹å¼è¾“å‡ºï¼Œæ®µè½æ¸…æ™°ï¼Œæ•°å€¼æ˜ç¡®\n"
            )
            advice_text = _safe_llm_answer(prompt, ctx, srcs, _tdee_advice_fallback(parsed, res))

        final_text = content if not wants else (content + "\n\n" + advice_text)
        state["messages"].append(AIMessage(content=final_text))

        state["tool_outputs"] = out
        state["need_clarify"] = None
        return state

    # ==== æŠ¤è‚¤å»ºè®® ====
    elif state.get("route") == "skin":
        parsed, missing = _parse_skin(text, prof)
        if missing:
            state["need_clarify"] = {
                "tool": "skincare",
                "missing": missing,
                "hint": "ç¤ºä¾‹ï¼šæ•æ„Ÿè‚Œï¼›æˆ–ï¼šå¤§å¹²çš®/æ··æ²¹ï¼›å¯å†™ï¼šæ™šä¸ŠAé†‡ã€ç™½å¤©VCï¼ˆå¯ä¸å†™ï¼‰"
            }
            state["tool_outputs"] = []
            return state

        # å·¥å…·è®¡ç®—ï¼ˆç»“æ„åŒ–è§„åˆ™ï¼‰
        res = skincare_tool(**parsed.model_dump())
        out.append({
            "tool": "skincare",
            "input": parsed.model_dump(),
            "result": res,
            "assumption": "ä»æ–‡æœ¬/ç”»åƒè§£æ"
        })
        PROFILE.update(
            skin_type=parsed.skin_type,
            actives_in_use=parsed.actives_in_use,
            concerns=parsed.concerns
        )

        # æ„é€  LLM Promptï¼ˆè®©æ¨¡å‹ç”Ÿæˆè‡ªç„¶è¯­è¨€è§£é‡Šï¼‰
        ctx_json = json.dumps(res, ensure_ascii=False, indent=2)
        user_prompt = (
            f"ç”¨æˆ·è‚¤è´¨ï¼š{parsed.skin_type}\n"
            f"åœ¨ç”¨æ´»æ€§ï¼š{parsed.actives_in_use}\n"
            f"ä¸»è¦é—®é¢˜ï¼š{parsed.concerns}\n\n"
            f"ç³»ç»Ÿè§„åˆ™ç»“æœï¼š\n{ctx_json}\n\n"
            "è¯·ä»¥æ¾³æ´²çš®è‚¤ç®¡ç†ä¸“å®¶çš„èº«ä»½å›ç­”ï¼š\n"
            "1ï¸âƒ£ è¯´æ˜è¿™ç§è‚¤è´¨çš„å…¸å‹ç‰¹å¾ä¸é£é™©ï¼›\n"
            "2ï¸âƒ£ ç»“åˆæ¾³æ´²æ°”å€™ï¼ˆUVå¼ºã€å¹²ç‡¥ï¼‰ç»™å‡ºæ—©æ™šæŠ¤è‚¤å»ºè®®ï¼›\n"
            "3ï¸âƒ£ è‹¥æœ‰é…ä¼å†²çªï¼Œè¯·è§£é‡ŠåŸç†å¹¶æä¾›æ›¿ä»£æ­é…ï¼›\n"
            "4ï¸âƒ£ æœ€åç»™å‡ºä¸€æ®µé¼“åŠ±æ€§ç»“è¯­ï¼ˆè‡ªç„¶æ¸©æš–è¯­æ°”ï¼‰ã€‚\n"
            "è¾“å‡ºè¯­è¨€é£æ ¼åº”è‡ªç„¶ã€æœ‰æ¸©åº¦ã€æœ‰å±‚æ¬¡ã€‚"
        )

        # è°ƒç”¨ LLM + å…œåº•è¾“å‡º
        ctx, srcs = _ctx_and_sources(state, out)
        fallback = (
            f"**è‚¤è´¨è¯†åˆ«**ï¼š{parsed.skin_type}\n"
            f"**æ ¸å¿ƒæ€è·¯**ï¼š{res.get('general', 'åŸºç¡€ä¿æ¹¿é˜²æ™’')}\n"
            "ï¼ˆæ¨¡å‹æš‚ä¸å¯ç”¨ï¼Œå·²æä¾›è§„åˆ™å»ºè®®ï¼‰"
        )
        content = _safe_llm_answer(user_prompt, ctx, srcs, fallback)

        # å­˜å…¥æ¶ˆæ¯
        state["messages"].append(AIMessage(content=content))
        state["tool_outputs"] = out
        state["need_clarify"] = None
        return state

    # ==== é»˜è®¤ ====
    state["tool_outputs"] = out
    state["need_clarify"] = None
    return state

# ===== RAGï¼ˆHybridï¼‰=====
retriever = ChunkedTfidfRetriever(kb_dir="kb", enable_hybrid=True)

def rag_gather(text: str) -> List[dict]:
    docs = retriever.search(text, k=5)
    out = []
    for (t, m, _, cid) in docs:
        out.append({
            "path": m["path"], "snippet": t, "cite": cid,
            "score": m.get("score_hybrid", 0.0),
            "score_embed": m.get("score_embed", 0.0),
            "score_tfidf": m.get("score_tfidf", 0.0),
        })
    return out

def _ctx_and_sources(state: AgentState, extra_tools: List[dict]) -> Tuple[str,List[str]]:
    user = _last_text(state)
    retrieved = rag_gather(user)
    state["retrieved"] = retrieved
    lines, srcs = [], []
    for d in retrieved:
        lines.append(f"[{d['cite']}] {d['snippet']}")
        name = Path(d["path"]).name.replace(".md","")
        srcs.append(f"[{d['cite']}] {name} (hyb={d['score']:.3f}, emb={d['score_embed']:.3f}, tfidf={d['score_tfidf']:.3f})")
    if extra_tools:
        lines.append("\n[Tools]\n" + json.dumps(extra_tools, ensure_ascii=False, indent=2, default=str))
    return "\n".join(lines), srcs

# ===== LLM å…±ç”¨ =====
SYSTEM = ("You are a helpful Health & Wellness advisor. "
          "You can discuss nutrition, fitness, and skincare. "
          "Always be cautious: you are not a doctor; avoid diagnosis or prescriptions.")

def _llm_answer(user: str, ctx: str, sources_lines: List[str]) -> str:
    prompt = (f"### Instruction\n{user}\n\n"
              f"### Context (RAG/Tools)\n{ctx}\n"
              "### Requirements\n"
              "- Use bullet points and short paragraphs.\n"
              "- Offer 3â€“6 actionable steps.\n"
              "- If context is used, cite as [1], [2].\n"
              "- Be local to Australia when relevant.\n"
              "- Answer in Chinese if user spoke Chinese.\n")
    try:
        resp = CHAT.chat.completions.create( 
            model=MODEL,
            messages=[{"role":"system","content":SYSTEM},{"role":"user","content":prompt}],
            temperature=0.4,
        )
        content = resp.choices[0].message.content
        if sources_lines:
            content += "\n\nSources:\n" + "\n".join(sources_lines)
        return content
    except Exception as e:
        return f"æŠ±æ­‰ï¼Œå½“å‰æ¨¡å‹ä¸å¯ç”¨ã€‚\n[debug] {type(e).__name__}: {e}"

# å®‰å…¨ LLM
def _safe_llm_answer(user: str, ctx: str, sources_lines: List[str], fallback: str) -> str:
    try:
        txt = _llm_answer(user, ctx, sources_lines)
        if txt.strip().startswith("æŠ±æ­‰ï¼Œå½“å‰æ¨¡å‹ä¸å¯ç”¨"):
            return fallback + "\nï¼ˆç³»ç»Ÿæç¤ºï¼šæ¨¡å‹å“åº”è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•ï¼‰"
        return txt
    except Exception as e:
        return fallback + f"\nï¼ˆç³»ç»Ÿæç¤ºï¼š{type(e).__name__}ï¼Œè¯·ç¨åé‡è¯•ï¼‰"

def _append_once(state: AgentState, *chunks: str) -> None:
    """å°†å¤šä¸ªæ–‡æœ¬ç‰‡æ®µç”¨ç©ºè¡Œæ‹¼å¥½ï¼Œåª append ä¸€æ¬¡ã€‚"""
    text = "\n\n".join([c for c in chunks if c and c.strip()])
    state["messages"].append(AIMessage(content=text))

# å°†â€œå®å†µå¡ç‰‡â€æ¸²æŸ“ä¸ºç¡®å®šæ€§æ–‡æœ¬ï¼ˆä¸èµ° LLMï¼‰
def _render_observation_card(city_label: str, tz_id: str, dt: datetime,
                             cond: str, temp_c: float, humidity: Optional[int],
                             uv_index: float, aqi_val: int) -> str:  # NEW
    WEEKDAY_ZH = ["æ˜ŸæœŸä¸€","æ˜ŸæœŸäºŒ","æ˜ŸæœŸä¸‰","æ˜ŸæœŸå››","æ˜ŸæœŸäº”","æ˜ŸæœŸå…­","æ˜ŸæœŸæ—¥"]
    line_time = f"{dt.year}å¹´{dt.month:02d}æœˆ{dt.day:02d}æ—¥ï¼Œ{WEEKDAY_ZH[dt.weekday()] }ï¼Œ{dt:%H:%M}ï¼ˆ{tz_id}ï¼‰"
    hum = "-" if humidity is None else f"{humidity}%"
    return (
        f"**{city_label} å®å†µ**\n"
        f"- æœ¬åœ°æ—¶é—´ï¼š{line_time}\n"
        f"- å¤©æ°”ï¼š{cond}\n"
        f"- æ¸©åº¦ï¼š{temp_c}Â°C\n"
        f"- æ¹¿åº¦ï¼š{hum}\n"
        f"- UVï¼š{uv_index}\n"
        f"- AQIï¼š{aqi_val}\n"
    )

def fitness_agent_node(state: AgentState):
    """
    å¿ƒç†/æƒ…ç»ª â†’ è¿åŠ¨åŒ¹é…ï¼š
    - å…ˆç”¨ mood_to_workout_tool ç»™å‡ºç»“æ„åŒ–æ–¹æ¡ˆ
    - å†è¯· LLM ç”Ÿæˆè‡ªç„¶è¯­è¨€å»ºè®®
    - è‹¥ LLM ä¸å¯ç”¨ï¼Œç”¨å…œåº•æ¨¡æ¿ç›´æ¥è¾“å‡º
    """
    text = _last_text(state)
    mood = _detect_mood(text)

    # 1) å·¥å…·ç»“æœï¼ˆç»“æ„åŒ–ï¼‰
    plan = mood_to_workout_tool(mood)
    tool_out = [{"tool": "moodâ†’workout", "input": {"mood": mood}, "result": plan}]
    ctx, srcs = _ctx_and_sources(state, tool_out)

    # 2) è®© LLM ç”Ÿæˆâ€œå¯ç›´æ¥ç…§åšâ€çš„è®­ç»ƒå»ºè®®
    prompt = (
        "ç”¨æˆ·çš„å½“å‰æƒ…ç»ªä¸çŠ¶æ€å¦‚ä¸‹ï¼ˆä»æ–‡æœ¬è§£æï¼‰ï¼š\n"
        f"- mood: {mood}\n\n"
        "ä¸‹é¢æ˜¯æ ¹æ®æƒ…ç»ªåŒ¹é…å¾—åˆ°çš„ç»“æ„åŒ–è¿åŠ¨æ–¹æ¡ˆï¼ˆæ¥è‡ªå·¥å…·ï¼‰ï¼š\n"
        f"{json.dumps(plan, ensure_ascii=False)}\n\n"
        "è¯·æ®æ­¤ç»™å‡ºå¯æ‰§è¡Œè®­ç»ƒå»ºè®®ï¼Œè¦æ±‚ï¼š\n"
        "1) è®­ç»ƒç±»å‹ä¸å¼ºåº¦ï¼ˆå« RPE æˆ–å¿ƒç‡åŒºé—´ï¼‰ï¼›æ—¶é•¿/ç»„æ¬¡/ä¼‘æ¯ï¼›\n"
        "2) çƒ­èº«ä¸å†·å´æµç¨‹ï¼ŒåŠ å…¥ 2â€“3 åˆ†é’Ÿçš„å‘¼å¸ç»ƒä¹ è„šæœ¬ï¼›\n"
        "3) å®‰å…¨æ³¨æ„ä¸æ¢å¤ï¼ˆç¡çœ /è¡¥æ°´/é‡æ§/ç–¼ç—›å¤„ç†ï¼‰ï¼›\n"
        "4) è¯­æ°”åŒç†ã€é¼“åŠ±ï¼›ä¸­æ–‡è¦ç‚¹å¼è¾“å‡ºã€‚"
    )

    # 3) å…œåº•æ–‡æœ¬ï¼ˆä¸ä¾èµ– LLMï¼ŒæŒ‰æƒ…ç»ªç›´æ¥ç»™ï¼‰
    if mood == "anxious":
        fallback = (
            "**æƒ…ç»ªè¯†åˆ«**ï¼šç„¦è™‘/äº¢å¥‹æ„Ÿåé«˜ï¼›\n"
            "**å»ºè®®è®­ç»ƒ**ï¼šä½â€”ä¸­å¼ºåº¦æœ‰æ°§ï¼ˆå¿«èµ°/éª‘è¡Œ/æ¤­åœ† 20â€“30 åˆ†é’Ÿï¼ŒRPE 4â€“6ï¼‰ï¼Œé…åˆå…¨èº«èˆ’ç¼“æ‹‰ä¼¸ 8â€“10 åˆ†é’Ÿï¼›\n"
            "**å‘¼å¸è„šæœ¬**ï¼š4-4-4-4ï¼ˆå¸4ç§’-åœ4ç§’-å‘¼4ç§’-åœ4ç§’ï¼‰Ã— 8 è½®ï¼›æ­¥è¡Œæ—¶å°½é‡é¼»å¸é¼»å‘¼ï¼›\n"
            "**æ³¨æ„**ï¼šé¿å…é«˜å¼ºåº¦å†²åˆºä¸è¿‡é‡å’–å•¡å› ï¼›è‹¥å¿ƒæ‚¸/èƒ¸é—·æŒç»­æˆ–åŠ é‡ï¼Œåœæ­¢è¿åŠ¨å¹¶å°±åŒ»ï¼›\n"
            "**æ¢å¤**ï¼šæ¸©æ°´æ·‹æµ´ã€è¡¥æ°´ 300â€“500mlã€ç¡å‰ 5 åˆ†é’Ÿè…¹å¼å‘¼å¸ã€‚"
        )
    elif mood == "excited":
        fallback = (
            "**æƒ…ç»ªè¯†åˆ«**ï¼šå…´å¥‹/åŠ¨æœºé«˜ï¼›\n"
            "**å»ºè®®è®­ç»ƒ**ï¼šé«˜è´¨é‡åŠ›é‡ä¸ºä¸»ï¼ˆå…¨èº« 4â€“6 ä¸ªå¤åˆåŠ¨ä½œï¼Œ3â€“4 ç»„Ã—6â€“10 æ¬¡ï¼ŒRPE â‰¤8ï¼‰ï¼Œ\n"
            "å¯åŠ  8â€“12 åˆ†é’Ÿé—´æ­‡æœ‰æ°§ï¼ˆå¦‚ 8Ã—(30så¿«+60sæ…¢)ï¼‰ï¼›\n"
            "**çƒ­èº«/å†·å´**ï¼šå…³èŠ‚åŠ¨æ€çƒ­èº« 5 åˆ†é’Ÿï¼›ç»“æŸåå°è…¿/è‚¡å››å¤´/è…˜ç»³/èƒŒéƒ¨é™æ€æ‹‰ä¼¸å„ 30â€“45sï¼›\n"
            "**é‡æ§**ï¼šé¿å…â€œçˆ†é‡â€ï¼›æœ¬æ¬¡æ€»æ—¶é•¿ 45â€“60 åˆ†é’Ÿï¼›\n"
            "**æ¢å¤**ï¼šè®­ç»ƒå 30â€“60 åˆ†é’Ÿå†…è¡¥æ°´ç”µè§£è´¨ä¸ä¼˜è´¨è›‹ç™½ï¼›æ™šé—´ 7â€“9 å°æ—¶ç¡çœ ã€‚"
        )
    elif mood == "low":
        fallback = (
            "**æƒ…ç»ªè¯†åˆ«**ï¼šä½è½/èƒ½é‡ä½ï¼›\n"
            "**å»ºè®®è®­ç»ƒ**ï¼šèŠ‚å¾‹ç»´æŒä¸ºä¸»ï¼šå…¨èº«è½»é‡åŠ›é‡ 20â€“30 åˆ†é’Ÿï¼ˆæ¯åŠ¨ä½œ 2â€“3 ç»„Ã—10â€“12 æ¬¡ï¼ŒRPE 5ï¼‰ï¼Œ\n"
            "æˆ– 20 åˆ†é’Ÿè½»æ¾æ­¥è¡Œ/éª‘è¡Œï¼›\n"
            "**å‘¼å¸**ï¼šé¼»å¸ 4 ç§’-å£å‘¼ 6 ç§’ï¼ŒæŒç»­ 3â€“5 åˆ†é’Ÿï¼›\n"
            "**å°ç›®æ ‡**ï¼šåªè¦æ±‚å‡ºé—¨/æ¢è£…/å®Œæˆå‰ 10 åˆ†é’Ÿå³å¯ï¼Œå®Œæˆå³å¯ç®—èµ¢ï¼›\n"
            "**æ¢å¤**ï¼šæ¸©å’Œæ‹‰ä¼¸ã€è¡¥æ°´ 300mlã€è®°å½•ä¸€æ¬¡â€œå®Œæˆ âœ”â€ã€‚"
        )
    else:  # neutral / å…¶å®ƒ
        fallback = (
            "**æƒ…ç»ªè¯†åˆ«**ï¼šå¹³ç¨³/ä¸€èˆ¬ï¼›\n"
            "**å»ºè®®è®­ç»ƒ**ï¼šå¸¸è§„åŠ›é‡ + ä¸­ç­‰å¼ºåº¦æœ‰æ°§ï¼š\n"
            "- åŠ›é‡ï¼šå…¨èº« 5 ä¸ªåŠ¨ä½œï¼ˆè¹²/æ¨/æ‹‰/é«‹ä¼¸/æ ¸å¿ƒï¼‰ï¼Œ3Ã—8â€“12 æ¬¡ï¼ŒRPE 6â€“7ï¼›\n"
            "- æœ‰æ°§ï¼š20â€“30 åˆ†é’Ÿï¼Œèƒ½æµç•…å¯¹è¯ç•¥å¾®å–˜ï¼›\n"
            "**çƒ­èº«/å†·å´**ï¼šåŠ¨æ€çƒ­èº« 5â€² + æ”¶æ“æ‹‰ä¼¸ 8â€²ï¼›\n"
            "**æ¢å¤**ï¼šè›‹ç™½ 1.6 g/kgÂ·dã€æ—¥æ­¥æ•° 7kâ€“10kã€ç¡çœ  7â€“9hã€‚"
        )

    # ç”¨â€œå®‰å…¨ LLMâ€ç”Ÿæˆï¼Œæœ‰é—®é¢˜å°±è½å› fallback
    content = _safe_llm_answer(prompt, ctx, srcs, fallback)
    state["messages"].append(AIMessage(content=content))
    return state


def nutrition_agent_node(state: AgentState):
    text = _last_text(state)
    ctx, srcs = _ctx_and_sources(state, [])
    content = _llm_answer(text + "\n\nè¯·ç»™å‡ºï¼šâ‘ é¤æ¬¡ä¸å®é‡å»ºè®® â‘¡ç¤ºä¾‹é£Ÿè°±ï¼ˆå«é£ŸæåŠå…‹é‡ï¼‰â‘¢å¯åœ¨Coles/Woolworthsè´­ä¹°çš„é€šç”¨é£Ÿææ¸…å•ã€‚", ctx, srcs)
    state["messages"].append(AIMessage(content=content))
    return state

def mind_agent_node(state: AgentState):
    """
    çº¯å¿ƒç†/æƒ…ç»ªæŠšæ…°é€šé“ï¼ˆä¸åšè¿åŠ¨åŒ¹é…ï¼‰ï¼š
    - è°ƒ RAGï¼ˆåå‘ psychology kbï¼‰
    - ç”¨ _safe_llm_answer ç”ŸæˆåŒç†+å¯æ‰§è¡Œæƒ…ç»ªè°ƒèŠ‚æ–¹æ¡ˆ
    - LLM ä¸å¯ç”¨æ—¶èµ°å¿ƒç†æŠšæ…°å…œåº•æ¨¡æ¿ï¼ˆä¸è¾“å‡ºä»»ä½•è¿åŠ¨å»ºè®®ï¼‰
    """
    text = _last_text(state)

    extra_tools = [{
        "tool": "3min_breathing",
        "input": {},
        "result": {"guide": "é¼»å¸4ç§’-åœ4ç§’-å£å‘¼4ç§’-åœ4ç§’ Ã— 8â€“10è½®ï¼›é…åˆè‚©é¢ˆæ”¾æ¾ä¸æ­£å¿µæ ‡ç­¾ï¼šçœ‹è§â†’å¬è§â†’æ„Ÿè§‰ã€‚"}
    }]

    # æ£€ç´¢ psychology ç­‰ KBï¼ˆ_ctx_and_sources ä¼šæŠŠæ£€ç´¢ç»“æœå’Œ tools ä¸€èµ·æ”¾å…¥ä¸Šä¸‹æ–‡ï¼‰
    ctx, srcs = _ctx_and_sources(state, extra_tools)

    # æ˜ç¡®å‘Šè¯‰ LLMï¼šè¿™æ˜¯â€œå¿ƒç†æŠšæ…°â€è€Œéâ€œè¿åŠ¨åŒ¹é…â€
    prompt = (
        "è¯·ç”¨åŒç†ã€æ¸©å’Œä¸”ä¸è¯„åˆ¤çš„è¯­æ°”ï¼Œé’ˆå¯¹ç”¨æˆ·çš„å¿ƒç†/æƒ…ç»ªå›°æ‰°æä¾›æ”¯æŒä¸æŠšæ…°ï¼ˆä¸è¦ç»™è¿åŠ¨/è®­ç»ƒå»ºè®®ï¼‰ã€‚\n"
        "ç›®æ ‡ï¼šå¸®åŠ©å¯¹æ–¹å…ˆç¨³ä½èº«å¿ƒï¼Œå†ç»™å‡ºå¯æ‰§è¡Œçš„å°æ­¥éª¤ã€‚\n\n"
        "è¯·æŒ‰ä¸‹é¢ç»“æ„è¾“å‡ºï¼š\n"
        "1) å…ˆ**å‘½åæƒ…ç»ª**å¹¶éªŒè¯ï¼ˆåæ˜ å¼è†å¬ï¼Œ1â€“2 å¥å³å¯ï¼‰ã€‚\n"
        "2) **3 åˆ†é’Ÿç¨³æ€ç»ƒä¹ è„šæœ¬**ï¼š\n"
        "   - 30â€“60 ç§’åœ°é¢ç€åŠ›è§‰ï¼ˆè„šæŒ/åéª¨çš„è§¦åœ°æ„Ÿï¼‰\n"
        "   - 2â€“3 åˆ†é’ŸèŠ‚å¾‹å‘¼å¸ï¼ˆå¦‚ 4-4-4-4 ç›’å¼å‘¼å¸æˆ– 4-6 å‘¼å¸ï¼‰\n"
        "   - 30 ç§’æ„Ÿå®˜é”šå®šï¼ˆçœ‹è§/å¬è§/è§¦æ„Ÿå„ 1â€“2 ä¸ªï¼‰\n"
        "3) **å½“ä¸‹å¯ä»¥åšçš„ 3 ä¸ªå°æ­¥éª¤**ï¼ˆ<5 åˆ†é’Ÿå³å¯å®Œæˆï¼Œæ¸…å•å¼ï¼Œå«â€œè§¦å‘-è¡ŒåŠ¨-å¥–åŠ±â€ï¼‰ã€‚\n"
        "4) **è‡ªæˆ‘å…³æ€€ä¸è¾¹ç•Œ**ï¼ˆç¡çœ /ä¿¡æ¯æ‘„å…¥/ä¸äººè”ç³»çš„å»ºè®®ï¼Œé¿å…è‡ªè´£ç”¨è¯­ï¼‰ã€‚\n"
        "5) è‹¥å‡ºç°**é£é™©ä¿¡å·**ï¼ˆå¦‚æŒç»­å¤±çœ >2å‘¨ã€å¼ºçƒˆç»æœ›/è‡ªä¼¤æƒ³æ³•ç­‰ï¼‰ï¼Œè¯·æ¸©æŸ”æé†’å¯»æ±‚ä¸“ä¸šæ”¯æŒä¸çƒ­çº¿ä¿¡æ¯ï¼ˆå¦‚ Beyond Blueï¼š1300 22 4636ï¼›Lifelineï¼š13 11 14ï¼‰ã€‚\n"
        "6) å…¨æ–‡ä¸æ¶‰åŠå¡è·¯é‡Œã€è®­ç»ƒã€è·‘æ­¥ã€HIIT ç­‰ä»»ä½•è¿åŠ¨å»ºè®®ã€‚\n"
        "å¦‚ç”¨åˆ°çŸ¥è¯†åº“å†…å®¹è¯·ä»¥ [1]ã€[2] æ ‡æ³¨ã€‚\n"
        f"\nç”¨æˆ·æ¶ˆæ¯ï¼š{text}\n"
    )

    # å…œåº•æ–‡æœ¬
    fallback = (
        "ä½ ç°åœ¨æ‰¿å—ç€ä¸å°‘å‹åŠ›ï¼Œè¿™å¾ˆä¸å®¹æ˜“ã€‚æˆ‘å¬è§ä½ åœ¨æ‹…å¿ƒã€ä¹Ÿåœ¨åŠªåŠ›æ’‘ç€ã€‚å…ˆä¸æ€¥ç€è§£å†³æ‰€æœ‰é—®é¢˜ï¼Œ"
        "æˆ‘ä»¬å…ˆæŠŠèº«å¿ƒç¨³ä½ï¼š\n\n"
        "**3 åˆ†é’Ÿç¨³æ€ç»ƒä¹ **\n"
        "- 30 ç§’ç€åœ°ï¼šæ„Ÿå—è„šæŒæˆ–åéª¨çš„è§¦åœ°ç‚¹ï¼Œæ³¨æ„èº«ä½“ä¸åœ°é¢çš„æ¥è§¦ã€‚\n"
        "- 2 åˆ†é’ŸèŠ‚å¾‹å‘¼å¸ï¼šå¸æ°” 4 ç§’ â†’ åœ 4 ç§’ â†’ å‘¼æ°” 4 ç§’ â†’ åœ 4 ç§’ï¼Œé‡å¤ 8â€“10 è½®ï¼›å‘¼æ°”æ—¶åœ¨å¿ƒé‡Œé»˜å¿µâ€œæ¾â€ã€‚\n"
        "- 30 ç§’æ„Ÿå®˜é”šå®šï¼šç¯é¡¾å››å‘¨æ‰¾ 3 ä¸ªä½ èƒ½çœ‹è§çš„äº‹ç‰©ã€2 ä¸ªèƒ½å¬åˆ°çš„å£°éŸ³ã€1 ä¸ªè§¦æ„Ÿã€‚\n\n"
        "**é©¬ä¸Šèƒ½åšçš„å°æ­¥éª¤ï¼ˆå„<5åˆ†é’Ÿï¼‰**\n"
        "1) è§¦å‘ï¼šå€’ä¸€æ¯æ¸©æ°´ â†’ è¡ŒåŠ¨ï¼šæ…¢æ…¢å– 5â€“10 å£ï¼Œæ„Ÿå—æ¸©åº¦ â†’ å¥–åŠ±ï¼šç»™è‡ªå·±ä¸€ä¸ªâ€œæˆ‘åœ¨ç…§é¡¾è‡ªå·±â€çš„æ‰“å‹¾æ ‡è®°ã€‚\n"
        "2) è§¦å‘ï¼šæ‰‹æœºé—¹é’Ÿ â†’ è¡ŒåŠ¨ï¼šç»™ä¿¡ä»»çš„äººå‘ä¸€å¥â€œæˆ‘ç°åœ¨æœ‰ç‚¹éš¾ï¼Œèƒ½å¬æˆ‘è¯´ 3 åˆ†é’Ÿå—ï¼Ÿâ€ â†’ å¥–åŠ±ï¼šå‘¼å¸ 4-6 ä¸¤è½®ã€‚\n"
        "3) è§¦å‘ï¼šæ¡Œé¢ä¾¿ç­¾ â†’ è¡ŒåŠ¨ï¼šå†™ä¸‹æ˜å¤©æƒ³å®Œæˆçš„**æœ€å°ä»»åŠ¡**ï¼ˆå¯åœ¨ 10â€“15 åˆ†é’Ÿå†…å®Œæˆï¼‰â†’ å¥–åŠ±ï¼šæ’­æ”¾ä¸€é¦–è½»éŸ³ä¹ã€‚\n\n"
        "**è‡ªæˆ‘å…³æ€€ä¸è¾¹ç•Œ**\n"
        "- ä»Šæ™šå°½é‡æå‰ä¸ŠåºŠ 30 åˆ†é’Ÿï¼Œç¡å‰åš 3 åˆ†é’Ÿå‘¼å¸ï¼›\n"
        "- ç»™è‡ªå·±ä¸€ä¸ªâ€œä¿¡æ¯æ­¢æŸç‚¹â€ï¼šç¡å‰ 1 å°æ—¶ä¸åˆ·å·¥ä½œç›¸å…³ä¿¡æ¯ï¼›\n"
        "- è‹¥è¿ç»­ä¸¤å‘¨æƒ…ç»ªä½è½ã€ç¡ä¸å¥½ï¼Œæˆ–å‡ºç°è‡ªä¼¤/æ— æœ›çš„å¿µå¤´ï¼Œè¯·å°½å¿«è”ç³»ä¸“ä¸šæ”¯æŒï¼š\n"
        "  â€¢ Beyond Blueï¼š1300 22 4636    â€¢ Lifelineï¼š13 11 14\n"
        "ä½ å·²ç»åœ¨åŠªåŠ›äº†ï¼Œå…è®¸è‡ªå·±æ…¢ä¸‹æ¥ï¼Œä¸€æ¬¡åªè¿ˆä¸€å°æ­¥å°±å¥½ã€‚"
    )

    content = _safe_llm_answer(prompt, ctx, srcs, fallback)
    state["messages"].append(AIMessage(content=content))
    return state

def greet_node(state: AgentState):
    """
    ç”¨ LLM ç”Ÿæˆè‡ªç„¶è¯­è¨€é—®å€™ä¸è‡ªæˆ‘ä»‹ç»ï¼Œæ›¿ä»£å›ºå®šæ¨¡æ¿ã€‚
    ä¸æ”¹è·¯ç”±/æ£€ç´¢/å·¥å…·ï¼Œä»…æ­¤èŠ‚ç‚¹è¡Œä¸ºå˜æ›´ã€‚
    """
    user_text = _last_text(state)
    profile = PROFILE.load() if "PROFILE" in globals() else {}
    # ç”¨ç”»åƒé‡Œå¯èƒ½çš„æ—¶åŒºï¼ˆæ²¡æœ‰å°±é»˜è®¤æ‚‰å°¼ï¼‰
    tz = profile.get("tz_id") or "Australia/Sydney"
    try:
        now_tz = datetime.now(pytz.timezone(tz))
    except Exception:
        now_tz = datetime.now(pytz.timezone("Australia/Sydney"))

    example_pool = [
        "æ‚‰å°¼ä»Šå¤©å¤©æ°”ï¼ˆæˆ–ç°åœ¨æ‚‰å°¼æ—¶é—´ï¼‰",
        "ç€æ–¯å’Œé˜¿å¾·è±å¾·ä»Šå¤©å¯¹æ¯”ä¸€ä¸‹å¤©æ°”",
        "å¢¨å°”æœ¬æœªæ¥7å¤©å¤©æ°”åŠå‡ºè¡Œå»ºè®®",
        "å¸®æˆ‘ç®—ä¸‹TDEEï¼šå¥³ 26å² 165cm 55kg ä¸­ç­‰æ´»åŠ¨",
        "æ•æ„Ÿè‚Œæ™šä¸Šç”¨Aé†‡ï¼Œç™½å¤©æ€ä¹ˆæŠ¤è‚¤ï¼Ÿ",
    ]
    examples = ", ".join(random.sample(example_pool, k=2))

    ctx, srcs = _ctx_and_sources(state, [])

    prompt = f"""
ä½ æ˜¯ LumaWellï¼Œä¸€ä½â€œå¥åº·ä¸å‡ºè¡Œâ€åŠ©æ‰‹ã€‚è¯·æ ¹æ®åœºæ™¯ï¼Œç”¨**è‡ªç„¶è¯­è¨€**å’Œç”¨æˆ·æ‰“æ‹›å‘¼å¹¶è‡ªæˆ‘ä»‹ç»ï¼Œé¿å…æ¨¡æ¿åŒ–ã€é¿å…åˆ—è¡¨/æ ‡é¢˜ã€‚
è¦æ±‚ï¼š
- å…ˆä¸€å¥ç®€çŸ­é—®å€™ï¼Œå¹¶æŒ‰å½“åœ°æ—¶é—´æ®µï¼ˆæ—©/åˆ/æ™šï¼‰é€‰æ‹©åˆé€‚æªè¾ã€‚
- ç”¨ 1â€“2 å¥æ¦‚æ‹¬ä½ èƒ½åšçš„äº‹ï¼ˆå®æ—¶å¤©æ°”/ä¸¤åŸå¯¹æ¯”/1~14å¤©é¢„æŠ¥ + æˆ·å¤–å»ºè®®ï¼›BMI/TDEEï¼›æŠ¤è‚¤ï¼›é¥®é£Ÿä¸æƒ…ç»ªç»ƒä¹ ï¼‰ï¼Œè¯­æ°”è½»æ¾äº²åˆ‡ã€‚
- ç»™ 1â€“2 ä¸ªè´´è¿‘ç”¨æˆ·çš„ç¤ºä¾‹é—®æ³•ï¼ˆå¯ä»â€œç¤ºä¾‹åº“â€æŒ‘é€‰æˆ–æ”¹å†™ï¼Œä¸è¦é€æ¡ç½—åˆ—ï¼‰ã€‚
- å…¨æ–‡ 2â€“4 å¥ï¼Œä¸è¦ä½¿ç”¨é¡¹ç›®ç¬¦å·æˆ–æ ‡é¢˜ã€‚

ç°åœ¨å½“åœ°æ—¶é—´ï¼š{now_tz:%Y-%m-%d %H:%M}ï¼ˆ{tz}ï¼‰
ç”¨æˆ·åˆšåˆšè¯´ï¼šâ€œ{user_text}â€
ç¤ºä¾‹åº“ï¼ˆä¾›ä½ å‚è€ƒä¸æ”¹å†™ï¼Œä¸è¦é€å­—ç…§æ¬ï¼‰ï¼š{examples}
è¯·ç”¨ä¸­æ–‡è¾“å‡ºã€‚
""".strip()

    fallback = "å—¨ï¼æˆ‘æ˜¯ä½ çš„å¥åº·ä¸å‡ºè¡ŒåŠ©æ‰‹ LumaWellã€‚å¯ä»¥å¸®ä½ çœ‹å½“åœ°å¤©æ°”ä¸æˆ·å¤–æ—¶æ®µã€åšä¸¤åŸå¯¹æ¯”ï¼Œæˆ–è®¡ç®— BMI/TDEEã€ç»™æŠ¤è‚¤ä¸é¥®é£Ÿå»ºè®®ã€‚æƒ³ä»å“ªä¸€é¡¹å¼€å§‹ï¼Ÿ"
    text = _safe_llm_answer(prompt, ctx, srcs, fallback)

    state["messages"].append(AIMessage(content=text))
    return state


def idle_node(state: AgentState):
    """
    ç©ºè¾“å…¥ï¼ˆåªå›è½¦/ç©ºç™½ï¼‰æ—¶ä¸å›å¤ä»»ä½•å†…å®¹ã€‚
    æ³¨æ„ï¼šä¸è¦å¾€ state["messages"] é‡Œ append æ¶ˆæ¯ã€‚
    """
    return state


def medical_agent_node(state: AgentState):
    text = _last_text(state)
    ctx, srcs = _ctx_and_sources(state, [])
    content = _llm_answer(text + "\n\nè¯·åšï¼šæŒ‡æ ‡è§£é‡Šï¼ˆé€šä¿—ç±»æ¯”ï¼‰+ ç”Ÿæ´»æ–¹å¼å¹²é¢„ + ä½•æ—¶å°±åŒ»/å¤æŸ¥æç¤ºï¼ˆéè¯Šæ–­ï¼‰ã€‚", ctx, srcs)
    state["messages"].append(AIMessage(content=content))
    return state

def environment_agent_node(state: AgentState):  # CHANGED
    text = _last_text(state)
    cities = _detect_au_cities(text)
    sub = state.get("sub_intent")
    wants = _wants_advice(text)   # æ˜¯å¦éœ€è¦å»ºè®®

     # (A)åŸå¸‚å¯¹æ¯”åŠ¨æ€æœªæ¥é¢„æŠ¥
    if sub in ["forecast_1","forecast_3","forecast_7","forecast_14"] and len(cities) >= 2:
        c1, c2 = cities[:2]
        days_map = {"forecast_1": 1, "forecast_3": 3, "forecast_7": 7, "forecast_14": 14}
        days = int(state.get("days_requested", days_map[sub]))
        offset = int(state.get("start_offset", 0))
        fetch_days = min(max(days + offset, days, 1), 14)
        fc1 = get_weather_forecast(c1, days=fetch_days)
        fc2 = get_weather_forecast(c2, days=fetch_days)

        days1 = fc1.get("forecast_days", [])
        days2 = fc2.get("forecast_days", [])
        start = min(max(offset, 0), max(len(days1) - 1, 0), max(len(days2) - 1, 0))
        end = min(start + max(days, 1), len(days1), len(days2))
        disp1 = days1[start:end]
        disp2 = days2[start:end]

        # ä»»ä¸€å¤±è´¥å°±å›é€€å„è‡ªå®å†µå¡ï¼ˆä¸å†™å»ºè®®ï¼‰
        if "error" in fc1 or "error" in fc2:
            out = []
            for city in [c1, c2]:
                w = get_weather_realtime(city)
                if "error" in w:
                    continue
                dt = dt_from_weather(w.get("localtime_epoch"), w.get("tz_id"))
                out.append(_render_observation_card(
                    f"{w.get('name')}, {w.get('region')}",
                    w.get("tz_id") or "Australia/Sydney",
                    dt,
                    w.get("condition","N/A"),
                    w.get("temp_c") or 22.0,
                    w.get("humidity"),
                    w.get("uv_index") or 6.0,
                    w.get("aqi") or 40
                ))
            if out:
                state["messages"].append(AIMessage(content="\n\n".join(out)))
            return state

        name1 = f"{fc1.get('name')}, {fc1.get('region')}"
        name2 = f"{fc2.get('name')}, {fc2.get('region')}"

        # â€”â€” æ ‡é¢˜ï¼ˆå»æ‰æ—¶åŒºä¸²è”ï¼‰â€”â€”
        title = f"### {name1} vs {name2} â€” æœªæ¥{len(disp1)}å¤©é€æ—¥å¯¹æ¯”ï¼ˆä»{['ä»Šå¤©','æ˜å¤©','åå¤©','å¤§åå¤©'][offset] if offset<4 else f'ç¬¬{offset}å¤©èµ·'}ï¼‰"

        # â€”â€” æ¯è¡ŒæŠŠâ€œåŒä¸€æ—¥æœŸçš„ä¸¤åŸâ€æ”¾ä¸€è¡Œï¼Œåˆ—æ›´å°‘æ›´æ¸…æ™° â€”â€” 
        headers = ["æ—¥æœŸ", name1, name2]
        rows = []

        for d1, d2 in zip(disp1, disp2):
            def pack(d):
                cond = _clean_cond(d.get("condition"))
                t    = _fmt_tpair(d.get("maxtemp_c"), d.get("mintemp_c"))
                avgT = f"{d.get('avgtemp_c','-')}Â°C" if d.get('avgtemp_c') is not None else "-"
                hum  = f"{int(round(float(d.get('avghumidity',0))))}%" if d.get('avghumidity') is not None else "-"
                r    = _fmt_rain(d.get("daily_chance_of_rain", 0))
                uv   = _fmt_uv(d.get("uv"))
                w    = _fmt_kph(d.get("maxwind_kph"))
                vis  = f"{d.get('avgvis_km','-')}km" if d.get('avgvis_km') is not None else "-"
                pres = (str(d.get("pressure_mb")) + "mb") if d.get("pressure_mb") is not None else "-"
                # æ‰“åŒ…æˆä¸€åˆ—æ–‡å­—ï¼ˆä¾¿äºä¸¤åŸå¹¶æ’å¯¹æ¯”ï¼‰
                return f"{cond} Â· {t} Â· å¹³å‡{avgT} Â· æ¹¿åº¦ {hum} Â· Rain {r} Â· Vis {vis} Â· Wind {w} Â· UV {uv} Â· P {pres}"
            rows.append([d1["date"], pack(d1), pack(d2)])

        table_text = title + "\n" + _mk_table(headers, rows, align=["<","<","<"])  # â† å»æ‰ max_col_widths
        if wants:
            ctx, srcs = _ctx_and_sources(state, [{
                "tool": "forecast_compare",
                "input": {"c1": name1, "c2": name2, "days": days, "offset": offset},
                "result": {"rows": len(disp1), "c1_days": disp1, "c2_days": disp2}
            }])

            payload = json.dumps({
                "city1": name1, "days1": disp1,
                "city2": name2, "days2": disp2
            }, ensure_ascii=False)

            compare_prompt = (
                f"ä»¥ä¸‹æ˜¯ä¸¤ä¸ªåŸå¸‚æœªæ¥{len(disp1)}å¤©é€æ—¥æ•°æ®ï¼ˆJSONï¼‰ï¼š\n{payload}\n\n"
                "è¯·å®Œæˆï¼š\n"
                "1) ä¸ºæ¯åº§åŸå¸‚æ ‡å‡º**æ›´é€‚åˆæˆ·å¤–**çš„æ—¥æœŸä¸å»ºè®®æ—¶æ®µï¼ˆæ—©/æ™šï¼‰ï¼Œç»™å‡ºç†ç”±ï¼ˆé™é›¨æ¦‚ç‡/é£/æ¸©åº¦/UVï¼‰ã€‚\n"
                "2) æ ‡å‡º**éœ€è¦è§„é¿**çš„æ—¥æœŸï¼ˆå¼ºé£/å¼ºé™é›¨/æç«¯æ¸©åº¦/é«˜UVï¼‰ï¼Œåˆ—å‡ºè§¦å‘é˜ˆå€¼ä¸åŸå› ã€‚\n"
                "3) ç»™å‡ºä¸¤åŸ**å·®å¼‚åŒ–**çš„é˜²æ™’/è¡¥æ°´/è£…å¤‡å»ºè®®ï¼ˆä¾‹å¦‚ SPF æ•°å€¼ã€æ¯å°æ—¶è¡¥æ°´é‡ã€æ˜¯å¦å¸¦é£å£³/é›¨å…·/é˜²æ™’è¡£ï¼‰ã€‚\n"
                "ç”¨ä¸­æ–‡è¦ç‚¹å¼è¾“å‡ºã€‚"
            )
            llm_text = _safe_llm_answer(compare_prompt, ctx, srcs, table_text + "\n\nï¼ˆè¯´æ˜ï¼šæ¨¡å‹æš‚æœªå“åº”ï¼Œå·²æä¾›å¯¹æ¯”è¡¨ï¼‰")
            _append_once(state, table_text, llm_text)
        else:
            _append_once(state, table_text)
        return state

        # ----------(B) åŠ¨æ€æœªæ¥é¢„æŠ¥ ----------
    if sub in ["forecast_1", "forecast_3", "forecast_7", "forecast_14"]:
        city_query = cities[0]
        days_map = {"forecast_1": 1, "forecast_3": 3, "forecast_7": 7, "forecast_14": 14}

        req_days = int(state.get("days_requested", days_map[sub]))
        offset = int(state.get("start_offset", 0))  # æ–°å¢ï¼šä» offset å¼€å§‹å±•ç¤º

        # ä¸ºäº†æ‹¿å¾—åˆ° offset ä¹‹åçš„çª—å£ï¼Œéœ€è¦å¤šå–ä¸€äº›å¤©æ•°
        fetch_days = min(max(req_days + offset, req_days, 1), 14)
        fc = get_weather_forecast(city_query, days=fetch_days)

        if "error" in fc:
            # é€€å›åˆ°å®æ—¶å¡ + æç¤º
            weather = get_weather_realtime(city_query)
            tz_id = (weather.get("tz_id") if "error" not in weather else "Australia/Sydney")
            dt = dt_from_weather(weather.get("localtime_epoch"), tz_id)
            city_label = city_query if "error" in weather else f"{weather.get('name')}, {weather.get('region')}"
            obs = _render_observation_card(city_label, tz_id, dt,
                                        weather.get("condition","N/A"),
                                        weather.get("temp_c") or 22.0,
                                        weather.get("humidity"),
                                        weather.get("uv_index") or 6.0,
                                        weather.get("aqi") or 40)
            note = f"ï¼ˆæœªèƒ½è·å–{req_days}å¤©é¢„æŠ¥ï¼š{fc['error']}ï¼‰"
            state["messages"].append(AIMessage(content=obs + "\n" + note))
            return state

        # ---------- è¾“å‡ºé˜¶æ®µ1ï¼šçº¯æ•°æ®è¡¨æ ¼ ----------
        city_label = f"{fc.get('name')}, {fc.get('region')}"
        tz_id = fc.get("tz_id") or "Australia/Sydney"

        all_days = fc.get("forecast_days", [])  # å¤©æ°”æœåŠ¡é€šå¸¸ day[0] = ä»Šå¤©
        if not all_days:
            state["messages"].append(AIMessage(content=f"æš‚æ—¶æ²¡æœ‰ {city_label} çš„é¢„æŠ¥æ•°æ®ã€‚"))
            return state

        # ä¾æ® offset æˆªå–ï¼šä» offset å¼€å§‹ï¼Œå– req_days å¤©ï¼ˆé˜²æº¢å‡ºï¼‰
        start = min(max(offset, 0), max(len(all_days) - 1, 0))
        end = min(start + max(req_days, 1), len(all_days))
        display_days = all_days[start:end]
        title_days = len(display_days)

        # æ ‡é¢˜åç¼€ï¼ˆå¯è¯»æ€§å¢å¼ºï¼‰
        if offset == 1:
            title_suffix = "ï¼ˆä»æ˜å¤©èµ·ï¼‰"
        elif offset == 2:
            title_suffix = "ï¼ˆä»åå¤©èµ·ï¼‰" if title_days > 1 else "ï¼ˆä»…åå¤©ï¼‰"
        elif offset == 3:
            title_suffix = "ï¼ˆä»å¤§åå¤©èµ·ï¼‰" if title_days > 1 else "ï¼ˆä»…å¤§åå¤©ï¼‰"
        else:
            title_suffix = ""

        title = f"### {city_label} â€” æœªæ¥{title_days}å¤©é¢„æŠ¥{title_suffix}ï¼ˆæœ¬åœ°æ—¶åŒºï¼‰"
        headers = ["æ—¥æœŸ", "å¤©æ°”", "é«˜/ä½", "å¹³å‡æ°”æ¸©", "æ¹¿åº¦", "é™é›¨", "é™æ°´", "èƒ½è§åº¦", "é£é€Ÿ", "UV", "æ°”å‹"]
        rows = []
        for d in display_days:
            rows.append([
                d["date"],
                _clean_cond(d.get("condition")),
                _fmt_tpair(d.get("maxtemp_c"), d.get("mintemp_c")),
                f"{d.get('avgtemp_c','-')}Â°C" if d.get('avgtemp_c') is not None else "-",
                f"{int(round(float(d.get('avghumidity',0))))}%" if d.get('avghumidity') is not None else "-",
                _fmt_rain(d.get("daily_chance_of_rain", 0)),
                _fmt_mm(d.get("totalprecip_mm")),
                f"{d.get('avgvis_km','-')}km" if d.get('avgvis_km') is not None else "-",
                _fmt_kph(d.get("maxwind_kph")),
                _fmt_uv(d.get("uv")),
                (str(d.get("pressure_mb")) + "mb") if d.get("pressure_mb") is not None else "-",
            ])

        table_text = title + "\n" + _mk_table(headers, rows, align=["<","<",">",">",">",">",">",">",">",">",">"])
        state["messages"].append(AIMessage(content=table_text))
            
        # ---------- è¾“å‡ºé˜¶æ®µ2ï¼šLLMå»ºè®®ï¼ˆåŸé€»è¾‘ä¿ç•™ï¼‰ ----------
        if _wants_advice(text):
            ctx, srcs = _ctx_and_sources(state, [{
                "tool": "forecast",
                "input": {"city": city_query, "days": req_days, "offset": offset},
                "result": {"records": len(display_days)}
            }])
            summary_prompt = (
                f"ä»¥ä¸‹æ˜¯{city_label}æœªæ¥{title_days}å¤©ï¼ˆoffset={offset}ï¼‰çš„å¤©æ°”æ•°æ®ï¼Œè¯·åˆ†æï¼š\n"
                f"{json.dumps(display_days, ensure_ascii=False)}\n\n"
                "è¯·è¾“å‡ºï¼š\n"
                "1) å¤©æ°”è¶‹åŠ¿ï¼ˆæ¸©åº¦ã€é™é›¨ã€UVå˜åŒ–ï¼‰\n"
                "2) é€‚åˆæˆ·å¤–æ´»åŠ¨çš„æ—¥æœŸä¸æ—¶æ®µ\n"
                "3) éœ€è§„é¿çš„å¤©æ°”ä¸åŸå› \n"
                "4) é˜²æ™’ä¸è£…å¤‡å»ºè®®ã€‚\n"
                "è¾“å‡ºæ ¼å¼åº”æ¸…æ™°åˆ†å±‚ï¼Œç”¨è¦ç‚¹å¼ä¸­æ–‡è¯´æ˜ã€‚"
            )
            fallback = table_text + "\n\nï¼ˆè¯´æ˜ï¼šæ¨¡å‹ç”Ÿæˆæš‚æ—¶ä¸å¯ç”¨ï¼Œå·²æä¾›é€æ—¥è¡¨æ ¼ä¾›å‚è€ƒï¼‰"
            advice_text = _safe_llm_answer(summary_prompt, ctx, srcs, fallback)
            state["messages"][-1] = AIMessage(content=(table_text + "\n\n" + advice_text).strip())
        return state


       # ---------- (C) ä¸¤åŸå¯¹æ¯”ï¼ˆç¡®å®šæ€§ + LLMå¢å¼ºï¼‰ ----------
    if sub == "compare" and len(cities) >= 2:
        c1, c2 = cities[:2]
        w1 = get_weather_realtime(c1)
        w2 = get_weather_realtime(c2)

        def _norm(w, default_city):
            if "error" in w:
                return {
                    "city": default_city,
                    "tz_id": "Australia/Sydney",
                    "dt": dt_from_weather(None, "Australia/Sydney"),
                    "temp_c": 22.0, "uv": 6.0, "aqi": 40,
                    "cond": f"N/Aï¼ˆ{w['error']}ï¼‰",
                    "humidity": None,
                }
            dt = dt_from_weather(w.get("localtime_epoch"), w.get("tz_id"))
            return {
                "city": f"{w.get('name')}, {w.get('region')}ï¼ˆ{w.get('tz_id')}ï¼‰",
                "tz_id": w.get("tz_id"),
                "dt": dt,
                "temp_c": w.get("temp_c"),
                "uv": w.get("uv_index"),
                "aqi": w.get("aqi"),
                "cond": w.get("condition", "N/A"),
                "humidity": w.get("humidity"),
            }

        a = _norm(w1, c1)
        b = _norm(w2, c2)

        title = f"### ä»Šæ—¥å¤©æ°”å¯¹æ¯”"
        headers = ["æŒ‡æ ‡", a["city"], b["city"]]
        rows = [
            ["æœ¬åœ°æ—¶é—´", f"{a['dt']:%Y-%m-%d %H:%M}", f"{b['dt']:%Y-%m-%d %H:%M}"],
            ["å¤©æ°”",      _clean_cond(a["cond"]),       _clean_cond(b["cond"])],
            ["æ°”æ¸©",      f"{a['temp_c']}Â°C",           f"{b['temp_c']}Â°C"],
            ["æ¹¿åº¦",      "-" if a['humidity'] is None else f"{a['humidity']}%",
                        "-" if b['humidity'] is None else f"{b['humidity']}%"],
            ["UV",        _fmt_uv(a["uv"]),             _fmt_uv(b["uv"])], 
            ["AQI",       a["aqi"],                     b["aqi"]],
        ]

        table_text = title + "\n" + _mk_table(headers, rows, align=["<","<","<"])  # å»æ‰ max_col_widths
        # ä¸ºäº†æ ‡é¢˜æ›´å¹²å‡€ï¼Œè¿™é‡ŒæŠŠ a["city"] ä¸­çš„ â€œï¼ˆtz_idï¼‰â€ å»æ‰ï¼Œä»…ä¿ç•™ â€œåŸå¸‚, å·/çœâ€
        a_label = a["city"].split("ï¼ˆ")[0]
        b_label = b["city"].split("ï¼ˆ")[0]

        full_a = "" if "error" in w1 else _render_full_realtime_table(
            a_label,
            w1,
            show_header=True,
            dedupe_basics=False,   # æ˜¾ç¤ºâ€œå…¨éƒ¨æŒ‡æ ‡â€ï¼šåŸºç¡€é¡¹ + æ‰©å±•é¡¹
            dt=a["dt"],            # è¡¨å¤´å‰åŠ â€œæœ¬åœ°æ—¶é—´ï¼šYYYY-MM-DD HH:MMï¼ˆtzï¼‰â€
            tz_id=a["tz_id"],
            show_time=True
        )
        full_b = "" if "error" in w2 else _render_full_realtime_table(
            b_label,
            w2,
            show_header=True,
            dedupe_basics=False,
            dt=b["dt"],
            tz_id=b["tz_id"],
            show_time=True
        )
        full_block = "\n\n".join([full_a, full_b]).strip()

        if not wants:
            _append_once(state, table_text, full_block)
            return state

        # å·¥å…·å»ºè®®
        advice_a = uv_aqi_advice_tool(a["temp_c"], a["uv"], a["aqi"])
        advice_b = uv_aqi_advice_tool(b["temp_c"], b["uv"], b["aqi"])
        advice_text = (
            f"**{a['city']}**\n"
            f"- ä»Šæ—¥æœ€ä½³æˆ·å¤–æ—¶æ®µï¼š{advice_a['best_window']}\n"
            f"- æ³¨æ„äº‹é¡¹ï¼š{'ï¼›'.join(advice_a['notes'])}\n\n"
            f"**{b['city']}**\n"
            f"- ä»Šæ—¥æœ€ä½³æˆ·å¤–æ—¶æ®µï¼š{advice_b['best_window']}\n"
            f"- æ³¨æ„äº‹é¡¹ï¼š{'ï¼›'.join(advice_b['notes'])}\n"
        )

        # LLM ç»¼åˆåˆ†æ
        ctx, srcs = _ctx_and_sources(state, [{
            "tool": "compare_weather",
            "input": {"city1": a["city"], "city2": b["city"]},
            "result": {"a": a, "b": b}
        }])
        compare_prompt = (
            f"ä»¥ä¸‹æ˜¯ä¸¤ä¸ªåŸå¸‚çš„å¤©æ°”æ•°æ®ï¼š\n{table_text}\n\n"
            "è¯·åˆ†æï¼š\n"
            "1) å“ªä¸ªåŸå¸‚ä»Šæ—¥æ›´é€‚åˆæˆ·å¤–æ´»åŠ¨ï¼Ÿ\n"
            "2) å„è‡ªéœ€è¦æ³¨æ„å“ªäº›é£é™©ï¼ˆUVã€ç©ºæ°”è´¨é‡ã€æ¸©åº¦ç­‰ï¼‰ï¼Ÿ\n"
            "3) è‹¥ç”¨æˆ·è®¡åˆ’é€šå‹¤/å‡ºè¡Œï¼Œè¯·ç»™å‡ºå·®å¼‚åŒ–å»ºè®®ã€‚\n"
            "è¯·ç”¨ä¸­æ–‡åˆ†æ¡è¯´æ˜ã€‚"
        )
        fallback = table_text + "\n\n" + advice_text + "\nï¼ˆè¯´æ˜ï¼šæ¨¡å‹æš‚æœªå“åº”ï¼Œå·²æä¾›å·¥å…·å¯¹æ¯”ç»“æœã€‚ï¼‰"
        llm_text = _safe_llm_answer(compare_prompt, ctx, srcs, fallback)

        # åªå‘ä¸€æ¡æ¶ˆæ¯ï¼šè¡¨æ ¼ + å·¥å…·å»ºè®® + LLM åˆ†æ
        _append_once(state, table_text, full_block, advice_text, llm_text)
        return state

    # ---------- (D) å•åŸï¼ˆå«â€œåªé—®æ—¶é—´/æ—¥æœŸâ€ï¼‰ ----------
    city_query = cities[0]
    weather = get_weather_realtime(city_query)

    if "error" in weather:
        temp_c, uv_index, aqi_val = 22.0, 6.0, 40
        tz_id, local_epoch = "Australia/Sydney", None
        city_label = city_query
        cond = "N/A"
        humidity = None
    else:
        temp_c  = weather.get("temp_c")   if weather.get("temp_c")   is not None else 22.0
        uv_index = weather.get("uv_index") if weather.get("uv_index") is not None else 6.0
        aqi_val = weather.get("aqi")      if weather.get("aqi")      is not None else 40
        tz_id = weather.get("tz_id") or "Australia/Sydney"
        local_epoch = weather.get("localtime_epoch")
        city_label = f"{weather.get('name')}, {weather.get('region')}"
        cond = weather.get("condition","N/A")
        humidity = weather.get("humidity")

    local_dt = dt_from_weather(local_epoch, tz_id)
    fc_today = get_weather_forecast(city_query, days=1)
    today_block = ""
    if "error" not in fc_today and fc_today.get("forecast_days"):
        today_block = _render_full_forecast_day_table(
            f"{fc_today.get('name')}, {fc_today.get('region')}",
            fc_today["forecast_days"][0]
        )

    # å®å†µå…¨æŒ‡æ ‡ï¼ˆæ˜¾ç¤ºæœ¬åœ°æ—¶é—´ï¼›å¹¶åŒ…å«åŸºç¡€é¡¹=â€œå…¨éƒ¨æŒ‡æ ‡â€ï¼‰
    full_table = ""
    if "error" not in weather:
        full_table = _render_full_realtime_table(
            city_label,
            weather,
            show_header=True,
            dedupe_basics=False,     # åŒ…å«åŸºç¡€é¡¹ï¼šå¤©æ°”/æ°”æ¸©/æ¹¿åº¦/UV/AQI
            dt=local_dt,             # æ˜¾ç¤ºæœ¬åœ°æ—¶é—´
            tz_id=tz_id,
            show_time=True
        )

    # ç»„åˆè¾“å‡ºï¼ˆå…ˆâ€œæ—¥çº§å®Œæ•´â€ï¼Œå†â€œå®æ—¶å…¨æŒ‡æ ‡â€ï¼‰
    state["messages"].append(AIMessage(content="\n\n".join([b for b in [today_block, full_table] if b]).strip()))
    if not wants:
        return state
    obs_table = today_block or full_table


    # === LLM å¢å€¼ ===
    advice = uv_aqi_advice_tool(temp_c, uv_index, aqi_val)
    tool_out = [{
        "tool": "weatherapiâ†’outdoor",
        "input": {"city": city_query, "temp_c": temp_c, "uv": uv_index, "aqi": aqi_val},
        "result": advice
    }]
    ctx, srcs = _ctx_and_sources(state, tool_out)

    SHOW_FALLBACK_NOTE = os.getenv("SHOW_FALLBACK_NOTE", "1")  
    fallback_note = "" if SHOW_FALLBACK_NOTE == "0" else "\nï¼ˆè¯´æ˜ï¼šæ¨¡å‹ç”Ÿæˆæš‚æ—¶ä¸å¯ç”¨ï¼Œå·²ç”¨å·¥å…·è§„åˆ™ç›´æ¥ç»™åˆ°å¯æ‰§è¡Œå»ºè®®ï¼‰"  # NEW

    fallback = (
        obs_table + "\n\n" + full_table + "\n"
        f"**ä»Šæ—¥æœ€ä½³æˆ·å¤–æ—¶æ®µ**ï¼š{advice['best_window']}\n"
        f"**æ³¨æ„äº‹é¡¹**ï¼š{'ï¼›'.join(advice['notes'])}\n"
        f"{fallback_note}"
    )


    prompt_user = (
    "è¯·åŸºäºä¸‹é¢ä¸¤å¼ è¡¨ç»™å‡º**å¯ç›´æ¥ç…§åš**çš„å»ºè®®ã€‚\n"
    "â€” è¡¨1ï¼šå®å†µæ¦‚è§ˆï¼ˆäººç±»å¯è¯»ï¼‰\n"
    f"{obs_table}\n\n"
    "â€” è¡¨2ï¼šå®å†µå…¨æŒ‡æ ‡ï¼ˆæœºå™¨å¯è¯»ã€å­—æ®µæ›´å…¨ï¼‰\n"
    f"{full_table}\n\n"
    f"æ ¸å¿ƒæ•°å€¼æç¤ºï¼šæ¸©åº¦ {temp_c}Â°Cï¼ŒUV {uv_index}ï¼ŒAQI {aqi_val}ã€‚\n\n"
    "è¯·è¾“å‡ºï¼š\n"
    "1) ä»Šæ—¥æœ€ä½³æˆ·å¤–æ—¶æ®µï¼ˆç»™åˆ°å…·ä½“é’Ÿç‚¹èŒƒå›´å¹¶ç®€è¿°ç†ç”±ï¼šæ¸©åº¦/é£/UV/é™æ°´ï¼‰\n"
    "2) é˜²æ™’/è¡¥æ°´/è£…å¤‡æ¸…å•ï¼ˆSPF/UPFã€æ¯å°æ—¶è¡¥æ°´é‡ã€æ˜¯å¦å¸¦é£å£³/é›¨å…·/å¢¨é•œ/é®é˜³å¸½ç­‰ï¼‰\n"
    "3) é€‚åˆçš„è‡ªç„¶ç–—æ„ˆæ´»åŠ¨ï¼ˆä¸¾1â€“3ä¸ªï¼Œè¯´æ˜ä¸ºä½•é€‚åˆå½“å‰æ¡ä»¶ï¼‰\n"
    "4) è‹¥æœ‰é£é™©ï¼ˆé«˜UVã€å¼ºé£ã€é™æ°´ã€ç©ºæ°”è´¨é‡åå·®ç­‰ï¼‰ï¼Œç»™å‡ºè§„é¿æ–¹æ³•æˆ–æ›¿ä»£æ–¹æ¡ˆã€‚\n"
    "è¦æ±‚ï¼šå¼•ç”¨ä¸Šè¿°å…·ä½“æ•°å€¼ï¼›ç”¨è¦ç‚¹å¼ä¸­æ–‡è¾“å‡ºï¼›å¦‚åŒ¹é…åˆ°æˆ·å¤–æ‰‹å†Œ/è£…å¤‡/é˜²æ™’ç­‰çŸ¥è¯†åº“ï¼Œè¯·ä»¥ [1]ã€[2]â€¦ æ ‡æ³¨ã€‚"
)

    content = _safe_llm_answer(prompt_user, ctx, srcs, fallback)

    NEEDLES = ["æœ€ä½³æˆ·å¤–æ—¶æ®µ", "æ³¨æ„äº‹é¡¹", "é˜²æ™’", "è¡¥æ°´", "è£…å¤‡", "è‡ªç„¶ç–—æ„ˆ"] 
    if not any(n in content for n in NEEDLES):  
        extra = (
            f"\n\n**ä»Šæ—¥æœ€ä½³æˆ·å¤–æ—¶æ®µ**ï¼š{advice['best_window']}\n"
            f"**æ³¨æ„äº‹é¡¹**ï¼š{'ï¼›'.join(advice['notes'])}\n"
        )
        content = content.strip() + extra  

    state["messages"].append(AIMessage(content=content))
    return state

# ===== é€šç”¨ RAG =====
def rag_node(state: AgentState):
    text = _last_text(state)
    ctx, srcs = _ctx_and_sources(state, [])
    content = _llm_answer(text, ctx, srcs)
    state["messages"].append(AIMessage(content=content))
    return state

# ===== å®‰å…¨èŠ‚ç‚¹ =====
def safety_node(state: AgentState):
    msg = ("ä½ æè¿°çš„æƒ…å†µå¯èƒ½æ¶‰åŠåŒ»ç–—ç´§æ€¥/è¯Šæ–­èŒƒç•´ã€‚æ­¤å¯¹è¯ä»…ä¾›å¥åº·å»ºè®®å­¦ä¹ ï¼Œ"
           "ä¸æ›¿ä»£ä¸“ä¸šåŒ»ç–—ã€‚è‹¥å‡ºç°æ€¥æ€§ç—‡çŠ¶æˆ–ä¸é€‚ï¼Œè¯·ç«‹å³è”ç³»å½“åœ°æ€¥æ•‘/å…¨ç§‘åŒ»ç”Ÿã€‚")
    state["messages"].append(AIMessage(content=msg))
    return state

def _bmi_weight_range(height_cm: float) -> Tuple[float, float]:
    """æŒ‰ BMI 18.5â€“24 è®¡ç®—å¯¹åº”å¥åº·ä½“é‡åŒºé—´ï¼ˆkgï¼Œä¿ç•™1ä½å°æ•°ï¼‰"""
    h = max(height_cm / 100.0, 0.5)  # é˜²å¾¡
    w_min = round(18.5 * h * h, 1)
    w_max = round(24.0 * h * h, 1)
    return w_min, w_max


def _bmi_advice_fallback(parsed: "BMIInput", res: Dict, wrange: Tuple[float, float]) -> str:
    """å½“ LLM ä¸å¯ç”¨æ—¶çš„ç¨³å¦¥å»ºè®®ï¼ˆåŸºäº BMI åˆ†ç±»ç»™å‡ºå¯æ‰§è¡Œæ–¹æ¡ˆï¼‰"""
    bmi = res.get("bmi")
    cat = (res.get("category") or "").strip()
    w_min, w_max = wrange
    h = parsed.height_cm
    w = parsed.weight_kg

    # åŸºäºåˆ†ç±»ç»™å‡ºçƒ­é‡æ–¹å‘ä¸ä¾§é‡
    if "åä½" in cat or "è¿‡ä½" in cat or "Under" in cat:
        goal = f"å¢é‡åˆ° {w_min}â€“{w_max} kg åŒºé—´å†…"
        kcal_tip = "æ¯æ—¥è¾ƒç»´æŒçƒ­é‡ +300~400 kcalï¼Œä¼˜å…ˆé«˜è›‹ç™½+é«˜èƒ½é‡å¯†åº¦ï¼ˆåšæœã€å…¨è„‚å¥¶ã€æ©„æ¦„æ²¹ï¼‰"
        train_tip = "ä¼˜å…ˆåŠ›é‡è®­ç»ƒï¼ˆæ¯å‘¨3æ¬¡ï¼Œæ¨/æ‹‰/è…¿æˆ–å…¨èº«ï¼‰ï¼ŒRPE 7â€“8ï¼Œæ¸è¿›åŠ é‡ï¼›æœ‰æ°§è½»åˆ°ä¸­ç­‰æ¯å‘¨1â€“2æ¬¡ç»´æŒå¿ƒè‚º"
    elif "æ­£å¸¸" in cat or "Normal" in cat:
        goal = f"ç»´æŒåœ¨ {w_min}â€“{w_max} kgï¼Œä½“æ€é‡å¡‘ï¼ˆå¢è‚Œå‡è„‚ï¼‰"
        kcal_tip = "å›´ç»•ç»´æŒçƒ­é‡Â±100~150 kcal å¾®è°ƒï¼›è›‹ç™½ â‰¥1.6 g/kgÂ·d"
        train_tip = "åŠ›é‡è®­ç»ƒæ¯å‘¨3â€“4æ¬¡ï¼ˆå…¨èº«æˆ–ä¸Šä¸‹è‚¢åˆ†åŒ–ï¼‰ï¼Œå¤åˆåŠ¨ä½œä¸ºä¸»ï¼›æœ‰æ°§æ¯å‘¨2â€“3æ¬¡ï¼ˆ30â€“40min ä¸­ç­‰å¼ºåº¦ï¼‰"
    else:
        goal = f"é€æ­¥å‡é‡è‡³ {w_max} kg é™„è¿‘ï¼ˆæˆ–åŒ»å˜±ç›®æ ‡ï¼‰"
        kcal_tip = "æ¯æ—¥è¾ƒç»´æŒçƒ­é‡ -300~500 kcalï¼Œè›‹ç™½ 1.6â€“2.0 g/kgÂ·dï¼Œä¼˜å…ˆé«˜çº¤å…¨è°·"
        train_tip = "åŠ›é‡è®­ç»ƒæ¯å‘¨3æ¬¡ç»´æŒè‚Œè‚‰ï¼ˆæ·±è¹²/ç¡¬æ‹‰/å§æ¨/åˆ’èˆ¹/æ¨ä¸¾ï¼‰ï¼›æœ‰æ°§æ¯å‘¨3â€“5æ¬¡ï¼ˆå¿«èµ°æˆ–éª‘è¡Œ 30â€“45minï¼‰"

    text = (
        f"### BMI å»ºè®®ï¼ˆfallbackï¼‰\n"
        f"- èº«é«˜ï¼š{h} cmï¼›ä½“é‡ï¼š{w} kgï¼›BMIï¼š{bmi}ï¼›åˆ†ç±»ï¼š{cat}\n"
        f"- å¥åº·ä½“é‡åŒºé—´ï¼ˆBMI 18.5â€“24ï¼‰ï¼šçº¦ **{w_min}â€“{w_max} kg**\n\n"
        f"**ç›®æ ‡**ï¼š{goal}\n"
        f"**çƒ­é‡åŸåˆ™**ï¼š{kcal_tip}\n\n"
        f"**ä¸€å‘¨è®­ç»ƒæ¨¡æ¿**ï¼š\n"
        f"- åŠ›é‡ï¼ˆ3æ¬¡ï¼‰ï¼šå…¨èº«æˆ–æ¨-æ‹‰-è…¿ï¼›æ¯æ¬¡ 5â€“6 ä¸ªåŠ¨ä½œ Ã— 3â€“4 ç»„ Ã— 6â€“12 æ¬¡ï¼ŒRPE 7â€“8ï¼›ç»„é—´ä¼‘æ¯ 60â€“120s\n"
        f"- æœ‰æ°§ï¼ˆ2â€“4æ¬¡ï¼‰ï¼šå¿«èµ°/æ¤­åœ†/éª‘è¡Œ 30â€“45minï¼Œä¸­ç­‰å¼ºåº¦ï¼ˆè¯´è¯ç•¥å–˜ï¼‰\n"
        f"- æœºåŠ¨ï¼šæ¯å¤© 10â€“15min å…³èŠ‚çµæ´»æ€§ä¸æ‹‰ä¼¸ï¼ˆé«‹ã€è¸ã€è‚©ï¼‰ï¼Œä¹…åäººç¾¤ä¼˜å…ˆé«‹å±ˆä¼¸ä¸èƒ¸æ¤ä¼¸å±•\n\n"
        f"**é¥®é£Ÿç»“æ„**ï¼š\n"
        f"- è›‹ç™½ï¼šâ‰¥1.6 g/kgÂ·dï¼ˆé¸¡èƒ¸/é±¼/ç˜¦ç‰›/é¸¡è›‹/å¸Œè…Šé…¸å¥¶/è±†åˆ¶å“ï¼‰\n"
        f"- ç¢³æ°´ï¼šä»¥å…¨è°·å’Œé«˜çº¤ä¸ºä¸»ï¼ˆç‡•éº¦ã€ç³™ç±³ã€å…¨éº¦é¢åŒ…ã€åœŸè±†/çº¢è–¯ï¼‰\n"
        f"- è„‚è‚ªï¼šåšæœã€ç‰›æ²¹æœã€æ©„æ¦„æ²¹ï¼›å‡å°‘æ·±åŠ å·¥ä¸åå¼è„‚è‚ª\n"
        f"- ç®€å•é¤ä¾‹ï¼š\n"
        f"  â€¢ æ—©ï¼šç‡•éº¦+ç‰›å¥¶+é…¸å¥¶+æµ†æœï¼›\n"
        f"  â€¢ åˆï¼šé¸¡èƒ¸/ä¸‰æ–‡é±¼+ç³™ç±³+è”¬èœæ²™æ‹‰ï¼›\n"
        f"  â€¢ æ™šï¼šç˜¦ç‰›/è±†è…+å…¨éº¦æ„é¢/åœŸè±†+æ—¶è”¬ï¼›\n"
        f"  â€¢ åŠ é¤ï¼šé¦™è•‰/åšæœ/è›‹ç™½é…¸å¥¶\n\n"
        f"**ç”Ÿæ´»æ–¹å¼**ï¼š\n"
        f"- NEATï¼šæ—¥æ­¥æ•° 7kâ€“10kï¼›æ¯å 45â€“60min èµ·èº«æ´»åŠ¨ 2â€“3min\n"
        f"- ç¡çœ ï¼š7â€“9hï¼Œå›ºå®šå°±å¯ä¸èµ·åºŠæ—¶é—´ï¼›æ°´åˆ†ï¼šä½“é‡Ã—30â€“40 ml/dï¼Œè¿åŠ¨å¤©è¡¥ç”µè§£è´¨\n"
        f"- ç›‘æµ‹ï¼šä½“é‡æ¯å‘¨æ³¢åŠ¨æ­£å¸¸ï¼Œå»ºè®®ä»¥ 4 å‘¨ç§»åŠ¨å¹³å‡çœ‹è¶‹åŠ¿ï¼›è®­ç»ƒè®°å½•é‡é‡/æ¬¡æ•°åšæ¸è¿›\n"
    )
    return text

# ===== é€šç”¨æ•°å€¼ä¸è¡¨æ ¼æ¸²æŸ“å·¥å…·ï¼ˆç»Ÿä¸€æ‰€æœ‰è¡¨æ ¼çš„å¯¹é½é£æ ¼ï¼‰ =====
def _fmt_uv(x):
    # æ”¹ï¼šä¸å†å–æ•´ï¼ŒåŸæ ·è¾“å‡ºï¼ˆå«å°æ•°ï¼‰
    return "-" if x is None else str(x)

def _fmt_kph(x):       return "-" if x is None else f"{int(round(float(x)))}kph"
def _fmt_mm(x):        return "-" if x is None else (f"{float(x):.1f}mm" if isinstance(x,(int,float,str)) else "-")
def _fmt_rain(p):      return "-" if p is None else f"{int(round(float(p)))}%"
def _fmt_tpair(hi, lo):return f"{int(round(float(hi)))}Â°/{int(round(float(lo)))}Â°"
def _clean_cond(s):    return (s or "").replace("|", "/").strip()

def _ellipsis(s, width):
    s = "-" if s is None else str(s)
    return s if len(s) <= width else (s[:max(1,width-1)] + "â€¦")

def _mk_table(headers, rows, align=None, max_col_widths=None):
    """
    ç”Ÿæˆç­‰å®½ ASCII è¡¨æ ¼ï¼Œå¹¶ç”¨ä»£ç å—åŒ…è£¹ã€‚
    - é»˜è®¤ä¸åšä»»ä½•æˆªæ–­ï¼›åªæœ‰æ˜¾å¼æä¾› max_col_widths æ—¶ï¼Œæ‰å¯¹ç›¸åº”åˆ—åšçœç•¥å·ã€‚
    """
    headers = [str(h) for h in headers]
    n = len(headers)
    align = align or ["<"] * n
    max_col_widths = max_col_widths or [None] * n

    # 1) æŒ‰å†…å®¹è®¡ç®—çœŸæ­£çš„åˆ—å®½ï¼ˆä¸è®¾ä¸Šé™ï¼‰
    widths = [len(h) for h in headers]
    for r in rows:
        for i, cell in enumerate(r):
            w = len(str(cell))
            if w > widths[i]:
                widths[i] = w

    # 2) æ¸²æŸ“æ—¶ï¼Œä»…å½“è¯¥åˆ—è®¾ç½®äº†ä¸Šé™ï¼Œæ‰è¿›è¡Œçœç•¥
    def fmt_cell_raw(s, i):
        a = align[i]
        return f"{s:{a}{widths[i]}}"

    def fmt_cell(s, i):
        s = "-" if s is None else str(s)
        if max_col_widths[i] is not None:
            s = _ellipsis(s, max_col_widths[i])
        return fmt_cell_raw(s, i)

    head = " | ".join(fmt_cell(h, i) for i, h in enumerate(headers))
    sep  = "-+-".join("-" * widths[i] for i in range(n))
    body = "\n".join(" | ".join(fmt_cell(str(c), i) for i, c in enumerate(r)) for r in rows)
    return "```\n" + head + "\n" + sep + "\n" + body + "\n```"

# ====== å®å†µå…¨æŒ‡æ ‡ï¼ˆå°½é‡åˆ—å‡º WeatherAPI å®æ—¶é‡Œå¯èƒ½å‡ºç°çš„å…³é”®å­—æ®µï¼›ç¼ºå¤±åˆ™è·³è¿‡ï¼‰ ======
def _fmt(s):  # é€šç”¨å­—ç¬¦ä¸²åŒ–
    return "-" if s is None else str(s)

def _join_nonempty(*parts):
    return " ".join([p for p in parts if p and str(p).strip() and p != "-"])

def _render_full_realtime_table(
    city_label: str,
    w: Dict,
    show_header: bool = True,
    dedupe_basics: bool = True,
    basics: Tuple[str, ...] = ("å¤©æ°”", "æ°”æ¸©", "æ¹¿åº¦", "UV", "AQI"),
    dt: Optional[datetime] = None,
    tz_id: Optional[str] = None,
    show_time: bool = False,
) -> str:
    # ---- å–å€¼ ----
    temp_c      = w.get("temp_c")
    feelslike_c = w.get("feelslike_c") or w.get("feels_like_c") or w.get("apparent_temp_c")
    cond        = w.get("condition") or w.get("text") or w.get("weather")
    humidity    = w.get("humidity")
    uv          = w.get("uv_index") if w.get("uv_index") is not None else w.get("uv")
    aqi         = w.get("aqi")
    wind_kph    = w.get("wind_kph") or w.get("wind_speed_kph")
    wind_dir    = w.get("wind_dir") or w.get("wind_direction")
    gust_kph    = w.get("gust_kph") or w.get("gust_speed_kph")
    pressure_mb = w.get("pressure_mb") or w.get("pressure") or w.get("pressure_hpa")
    cloud       = w.get("cloud")
    vis_km      = w.get("vis_km") or w.get("visibility_km")
    dew_c       = w.get("dewpoint_c") or w.get("dew_point_c")
    precip_mm   = w.get("precip_mm") or w.get("precip_1hr_mm") or w.get("rain_1h_mm")

    # ---- åŸºç¡€é¡¹ï¼ˆåªå®šä¹‰ä¸€æ¬¡ï¼Œä¸è¦é‡å¤ appendï¼‰----
    base_rows = [
        ["å¤©æ°”",  _fmt(_clean_cond(cond))],
        ["æ°”æ¸©",  _join_nonempty(_fmt(temp_c) + "Â°C", "(ä½“æ„Ÿ " + _fmt(feelslike_c) + "Â°C)" if feelslike_c is not None else "")],
        ["æ¹¿åº¦",  (_fmt(humidity) + "%") if humidity is not None else "-"],
        ["UV",    _fmt_uv(uv)],
        ["AQI",   _fmt(aqi)],
    ]

    # ---- æ‰©å±•é¡¹ ----
    extra_rows = []
    if wind_kph is not None:     extra_rows.append(["é£é€Ÿ/å‘", _join_nonempty(_fmt(int(round(float(wind_kph)))) + "kph", _fmt(wind_dir))])
    if gust_kph is not None:     extra_rows.append(["é˜µé£",    _fmt(int(round(float(gust_kph)))) + "kph"])
    if pressure_mb is not None:  extra_rows.append(["æ°”å‹",    _fmt(pressure_mb) + "mb"])
    if cloud is not None:        extra_rows.append(["äº‘é‡",    _fmt(cloud) + "%"])
    if vis_km is not None:       extra_rows.append(["èƒ½è§åº¦",  _fmt(vis_km) + "km"])
    if dew_c is not None:        extra_rows.append(["éœ²ç‚¹",    _fmt(dew_c) + "Â°C"])
    if precip_mm is not None:    extra_rows.append(["è¿‘é™æ°´",  _fmt(precip_mm) + "mm"])

    rows = extra_rows if dedupe_basics else (base_rows + extra_rows)
    if not rows:
        return ""

    time_line = f"æœ¬åœ°æ—¶é—´ï¼š{dt:%Y-%m-%d %H:%M}ï¼ˆ{tz_id or ''}ï¼‰\n" if (show_time and isinstance(dt, datetime)) else ""
    head = f"#### {city_label} â€”â€” å®å†µå…¨æŒ‡æ ‡" if show_header else ""
    block = _mk_table(["æŒ‡æ ‡","æ•°å€¼"], rows, align=["<","<"])
    return (time_line + (head + "\n" if head else "") + block).strip()

# ====== å•å¤©â€œé¢„æŠ¥-æ—¥çº§â€å®Œæ•´æŒ‡æ ‡è¡¨ï¼ˆç”¨äºä»Šå¤© or æœªæ¥çš„æ¯å¤©ï¼‰ ======
def _render_full_forecast_day_table(city_label: str, d: Dict) -> str:
    """
    ç”¨ forecast è¿”å›çš„å•æ—¥è®°å½• dï¼Œæ¸²æŸ“å°½é‡å…¨çš„â€œæ—¥çº§æŒ‡æ ‡â€è¡¨ã€‚
    å…¼å®¹ key ä¸å­˜åœ¨çš„æƒ…å†µï¼ˆç”¨ '-'ï¼‰ã€‚
    """
    def g(k, default="-"):
        v = d.get(k)
        return "-" if v is None else v

    rows = [
        ["å¤©æ°”",         _clean_cond(g("condition"))],
        ["é«˜/ä½",        _fmt_tpair(g("maxtemp_c"), g("mintemp_c"))],
        ["å¹³å‡æ°”æ¸©",     f"{g('avgtemp_c')}Â°C" if g('avgtemp_c') != "-" else "-"],
        ["ç›¸å¯¹æ¹¿åº¦(å‡å€¼)", f"{int(round(float(g('avghumidity'))))}%" if g('avghumidity') not in (None,"-") else "-"],
        ["é™é›¨æ¦‚ç‡",     _fmt_rain(g("daily_chance_of_rain", 0))],
        ["é™æ°´é‡(æ€»)",   _fmt_mm(g("totalprecip_mm"))],
        ["èƒ½è§åº¦(å‡å€¼)", f"{g('avgvis_km')}km" if g('avgvis_km') not in (None,"-") else "-"],
        ["æœ€å¤§é£é€Ÿ",     _fmt_kph(g("maxwind_kph"))],
        ["UV",           _fmt_uv(g("uv"))],
        # ä¸‹é¢å‡ ä¸ªå­—æ®µä¸åŒæ•°æ®æºå¯èƒ½æ²¡æœ‰ï¼Œå°½é‡å–åˆ°å°±æ˜¾ç¤º
        ["æ°”å‹(å‡å€¼)",   f"{g('pressure_mb')}mb" if g('pressure_mb') not in (None,"-") else "-"],
        ["äº‘é‡(å‡å€¼)",   f"{int(round(float(g('cloud'))))}%" if g('cloud') not in (None,"-") else "-"],
        ["éœ²ç‚¹(å‡å€¼)",   f"{g('dewpoint_c')}Â°C" if g('dewpoint_c') not in (None,"-") else "-"],
    ]
    head = f"#### {city_label} â€”â€” æ—¥çº§å®Œæ•´æŒ‡æ ‡ï¼ˆ{d.get('date','æœªçŸ¥æ—¥æœŸ')}ï¼‰"
    return head + "\n" + _mk_table(["æŒ‡æ ‡","æ•°å€¼"], rows, align=["<","<"])
